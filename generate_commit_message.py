#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Commit Message Generator
-----------------------
è‡ªåŠ¨åˆ†æGitæš‚å­˜åŒºå˜æ›´å¹¶ç”Ÿæˆç»“æ„åŒ–çš„æäº¤ä¿¡æ¯

ç”¨æ³•:
    python generate_commit_message.py
"""

import os
import re
import subprocess
from collections import defaultdict
from datetime import datetime

# æ·»åŠ å¸¸é‡å®šä¹‰
GITHUB_FILE_SIZE_LIMIT = 100 * 1024 * 1024  # GitHub é»˜è®¤å•ä¸ªæ–‡ä»¶å¤§å°é™åˆ¶ 100MB
GITHUB_RECOMMENDED_LIMIT = 50 * 1024 * 1024  # GitHub æ¨èå•ä¸ªæ–‡ä»¶ä¸è¶…è¿‡ 50MB
GITHUB_LFS_SUGGESTION = 5 * 1024 * 1024  # å»ºè®®ä½¿ç”¨ Git LFS çš„é˜ˆå€¼ 5MB


def run_git_command(command):
    """è¿è¡ŒGitå‘½ä»¤å¹¶è¿”å›è¾“å‡º"""
    try:
        result = subprocess.run(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            check=True,
            shell=True,
            encoding='utf-8',
            errors='ignore'
        )
        return result.stdout.strip()
    except subprocess.CalledProcessError as e:
        print(f"é”™è¯¯: Gitå‘½ä»¤æ‰§è¡Œå¤±è´¥: {e}")
        print(f"é”™è¯¯ä¿¡æ¯: {e.stderr}")
        return ""


def get_staged_files():
    """è·å–æ‰€æœ‰å·²æš‚å­˜æ–‡ä»¶çš„å˜æ›´çŠ¶æ€"""
    output = run_git_command("git diff --cached --name-status")
    if not output:
        return []

    changes = []
    for line in output.split('\n'):
        if not line.strip():
            continue

        parts = line.strip().split(maxsplit=1)
        if len(parts) < 2:
            continue

        status, filepath = parts
        changes.append((status, filepath))

    return changes


def analyze_changes(changes):
    """åˆ†æå˜æ›´å¹¶æŒ‰ç±»å‹å’Œç›®å½•è¿›è¡Œåˆ†ç»„"""
    if not changes:
        return {}, {}, {}

    # æŒ‰å˜æ›´ç±»å‹åˆ†ç»„
    status_groups = {
        'A': [],  # æ–°å¢
        'M': [],  # ä¿®æ”¹
        'D': [],  # åˆ é™¤
        'R': [],  # é‡å‘½å
        'C': [],  # å¤åˆ¶
        'Other': []  # å…¶ä»–å˜æ›´
    }

    # æŒ‰æ¨¡å—/åº”ç”¨åˆ†ç»„
    module_changes = defaultdict(lambda: {'A': [], 'M': [], 'D': [], 'R': [], 'Other': []})

    # æ–‡ä»¶ç±»å‹ç»Ÿè®¡
    file_types = defaultdict(int)

    for status, filepath in changes:
        # å¤„ç†çŠ¶æ€ä»£ç 
        base_status = status[0]  # å–é¦–å­—ç¬¦ä½œä¸ºåŸºæœ¬çŠ¶æ€
        if base_status in status_groups:
            status_groups[base_status].append(filepath)
        else:
            status_groups['Other'].append(filepath)

        # ç¡®å®šæ–‡ä»¶æ‰€å±æ¨¡å—
        module = determine_module(filepath)
        if base_status in module_changes[module]:
            module_changes[module][base_status].append(filepath)
        else:
            module_changes[module]['Other'].append(filepath)

        # ç»Ÿè®¡æ–‡ä»¶ç±»å‹
        file_ext = os.path.splitext(filepath)[1].lower()
        if file_ext:
            file_types[file_ext] += 1

    return status_groups, dict(module_changes), dict(file_types)


def determine_module(filepath):
    """æ ¹æ®æ–‡ä»¶è·¯å¾„ç¡®å®šæ¨¡å—/åº”ç”¨åç§°ï¼Œæ”¯æŒå¤šç§é¡¹ç›®ç»“æ„"""
    filepath = filepath.replace('\\', '/')  # ç»Ÿä¸€è·¯å¾„åˆ†éš”ç¬¦

    # é¢„å®šä¹‰ä¸€äº›ç‰¹æ®Šç›®å½•ä¸ä¸šåŠ¡æ¨¡å—çš„æ˜ å°„
    special_dirs = {
        'auth': 'è®¤è¯æˆæƒ',
        'users': 'ç”¨æˆ·ç®¡ç†',
        'tasks': 'ä»»åŠ¡ç®¡ç†',
        'data_source': 'æ•°æ®æº',
        'reports': 'æŠ¥è¡¨ç”Ÿæˆ',
        'dashboard': 'ä»ªè¡¨æ¿',
        'apis': 'APIå±‚',
        'api': 'APIå±‚',
        'core': 'æ ¸å¿ƒåŠŸèƒ½',
        'admin': 'ç®¡ç†ç•Œé¢',
        'settings': 'ç³»ç»Ÿé…ç½®',
        'utils': 'å·¥å…·å‡½æ•°',
        'middlewares': 'ä¸­é—´ä»¶',
        'migrations': 'æ•°æ®è¿ç§»',
        'tests': 'æµ‹è¯•å¥—ä»¶',
        'docs': 'æ–‡æ¡£'
    }

    # å¤„ç†Djangoåº”ç”¨
    django_app_match = re.search(r'wfgame-ai-server/apps/(\w+)/', filepath)
    if django_app_match:
        app_name = django_app_match.group(1)
        return f"apps/{special_dirs.get(app_name, app_name)}"

    # è¯†åˆ«å¸¸è§çš„é¡¹ç›®ç»“æ„æ¨¡å¼

    # Djangoé¡¹ç›®ç»“æ„
    django_pattern = r'/(?:apps/|[^/]+/)?([\w_]+)/'
    django_match = re.search(django_pattern, filepath)

    # Flask/é€šç”¨Pythoné¡¹ç›®ç»“æ„
    py_pattern = r'/(?:app/|src/|)?([\w_]+)/'
    py_match = re.search(py_pattern, filepath)

    # è¯†åˆ«ç‰¹å®šæ–‡ä»¶ç±»å‹çš„ç›®å½•
    if 'static/' in filepath or 'assets/' in filepath:
        return 'static'
    elif 'templates/' in filepath or 'views/' in filepath:
        return 'templates'
    elif 'docs/' in filepath or 'documentation/' in filepath:
        return 'docs'
    elif 'wfgame-ai-web/' in filepath:
        # æ£€æµ‹å‰ç«¯ä»£ç ä¸­çš„å…·ä½“æ¨¡å—
        front_module_match = re.search(r'wfgame-ai-web/(?:src/|app/|)?([\w_-]+)/', filepath)
        if front_module_match:
            front_module = front_module_match.group(1)
            if front_module in ['components', 'pages', 'layouts', 'store', 'utils', 'api']:
                return f'frontend/{front_module}'
        return 'frontend'

    # é…ç½®æ–‡ä»¶ç‰¹æ®Šå¤„ç†
    if any(filepath.endswith(ext) for ext in ['.ini', '.json', '.yaml', '.yml', '.config', '.conf', '.env']):
        return 'config'

    # æ ¹ç›®å½•çš„ç‰¹æ®Šæ–‡ä»¶
    if filepath.count('/') == 0:
        if filepath.endswith('.py'):
            return 'scripts'
        elif filepath in ['.gitignore', '.gitattributes', 'README.md', 'LICENSE']:
            return 'project'

    # ä½¿ç”¨è¯†åˆ«åˆ°çš„æ¨¡å—å
    if django_match:
        module_name = django_match.group(1)
        # å¦‚æœæ˜¯å·²çŸ¥çš„ç‰¹æ®Šç›®å½•ï¼Œä½¿ç”¨æ˜ å°„åç§°
        if module_name in special_dirs:
            return special_dirs[module_name]
        return module_name

    if py_match:
        module_name = py_match.group(1)
        if module_name in special_dirs:
            return special_dirs[module_name]
        return module_name

    # å›é€€æ–¹æ¡ˆï¼šä»è·¯å¾„ä¸­æå–å¯èƒ½çš„æ¨¡å—å
    path_parts = filepath.split('/')
    for part in path_parts:
        if part in special_dirs:
            return special_dirs[part]

    # æœ€ç»ˆå›é€€ï¼šè¯†åˆ«æ–‡ä»¶ç±»å‹
    if filepath.endswith('.py'):
        return 'python'
    elif filepath.endswith(('.js', '.ts', '.jsx', '.tsx', '.vue')):
        return 'frontend'
    elif filepath.endswith(('.html', '.css', '.scss', '.less')):
        return 'ui'

    # å…¶ä»–æ–‡ä»¶
    return 'other'


def get_change_summary(status_groups):
    """æ ¹æ®å˜æ›´çŠ¶æ€ç”Ÿæˆæ¦‚è¿°"""
    summary_parts = []

    if status_groups['A']:
        summary_parts.append(f"æ–°å¢äº† {len(status_groups['A'])} ä¸ªæ–‡ä»¶")

    if status_groups['M']:
        summary_parts.append(f"ä¿®æ”¹äº† {len(status_groups['M'])} ä¸ªæ–‡ä»¶")

    if status_groups['D']:
        summary_parts.append(f"åˆ é™¤äº† {len(status_groups['D'])} ä¸ªæ–‡ä»¶")

    if status_groups['R']:
        summary_parts.append(f"é‡å‘½åäº† {len(status_groups['R'])} ä¸ªæ–‡ä»¶")

    if not summary_parts:
        return "æœªæ£€æµ‹åˆ°æ–‡ä»¶å˜æ›´"

    return "ã€".join(summary_parts)


def format_filename(filename):
    """æ ¼å¼åŒ–æ–‡ä»¶åï¼Œç§»é™¤å¤šä½™çš„å¼•å·"""
    basename = os.path.basename(filename)
    # ç§»é™¤æ–‡ä»¶åä¸­å¯èƒ½çš„å¼•å·
    return basename.replace('"', '')

def get_module_details(module_changes):
    """ç”Ÿæˆæ¯ä¸ªæ¨¡å—çš„è¯¦ç»†å˜æ›´ä¿¡æ¯"""
    details = []

    # æŒ‰æ¨¡å—åç§°æ’åº
    for module, changes in sorted(module_changes.items()):
        # è·³è¿‡æ²¡æœ‰å˜æ›´çš„æ¨¡å—
        has_changes = any(changes[status] for status in changes)
        if not has_changes:
            continue

        module_lines = []

        # æ·»åŠ æ¨¡å—æ ‡é¢˜
        module_title = module.split('/')[-1] if '/' in module else module
        module_lines.append(f"{module_title}æ¨¡å—:")

        # æ·»åŠ è¯¦ç»†å˜æ›´
        if changes['A']:
            if len(changes['A']) <= 3:
                files = ", ".join(format_filename(f) for f in changes['A'])
                module_lines.append(f"  - æ–°å¢: {files}")
            else:
                module_lines.append(f"  - æ–°å¢äº† {len(changes['A'])} ä¸ªæ–‡ä»¶")

                # åˆ†ç±»æ–‡ä»¶
                py_files = [f for f in changes['A'] if f.endswith('.py')]
                if py_files:
                    py_types = classify_python_files(py_files)
                    for py_type, files in py_types.items():
                        if files:
                            module_lines.append(f"    - {py_type}: {len(files)}ä¸ª")

        if changes['M']:
            if len(changes['M']) <= 3:
                files = ", ".join(format_filename(f) for f in changes['M'])
                module_lines.append(f"  - ä¿®æ”¹: {files}")
            else:
                module_lines.append(f"  - ä¿®æ”¹äº† {len(changes['M'])} ä¸ªæ–‡ä»¶")

        if changes['D']:
            if len(changes['D']) <= 3:
                files = ", ".join(os.path.basename(f) for f in changes['D'])
                module_lines.append(f"  - åˆ é™¤: {files}")
            else:
                module_lines.append(f"  - åˆ é™¤äº† {len(changes['D'])} ä¸ªæ–‡ä»¶")

        details.append("\n".join(module_lines))

    return "\n".join(details)


def classify_python_files(files):
    """å¯¹Pythonæ–‡ä»¶è¿›è¡Œæ›´ç²¾ç¡®çš„åˆ†ç±»ï¼Œä¾¿äºæå–åŠŸèƒ½ç‰¹æ€§å’Œå˜æ›´ä»·å€¼"""
    categories = {
        "æ¨¡å‹å®šä¹‰": [],      # æ•°æ®æ¨¡å‹å±‚
        "è§†å›¾æ§åˆ¶": [],      # UIæ¸²æŸ“å’Œæ§åˆ¶å±‚
        "APIæ¥å£": [],       # REST APIæˆ–å…¶ä»–æ¥å£
        "URLé…ç½®": [],       # è·¯ç”±é…ç½®
        "åºåˆ—åŒ–å™¨": [],      # æ•°æ®åºåˆ—åŒ–
        "è¿ç§»æ–‡ä»¶": [],      # æ•°æ®åº“è¿ç§»
        "ä»»åŠ¡é˜Ÿåˆ—": [],      # å¼‚æ­¥ä»»åŠ¡å¤„ç†
        "æ•°æ®å¤„ç†": [],      # æ•°æ®åˆ†æå’Œå¤„ç†
        "å·¥å…·å‡½æ•°": [],      # é€šç”¨å·¥å…·
        "æ ¸å¿ƒé€»è¾‘": [],      # ä¸šåŠ¡æ ¸å¿ƒé€»è¾‘
        "é…ç½®ç®¡ç†": [],      # ç³»ç»Ÿé…ç½®
        "å®‰å…¨è®¤è¯": [],      # å®‰å…¨å’Œæƒé™ç›¸å…³
        "ä¸­é—´ä»¶": [],        # è¯·æ±‚/å“åº”å¤„ç†ä¸­é—´ä»¶
        "å•å…ƒæµ‹è¯•": [],      # æµ‹è¯•ä»£ç 
        "æ–‡æ¡£å·¥å…·": [],      # æ–‡æ¡£ç”Ÿæˆå’Œç®¡ç†
        "å…¶ä»–": []           # æœªå½’ç±»æ–‡ä»¶
    }

    for file in files:
        filepath = file.replace('\\', '/')  # ç»Ÿä¸€è·¯å¾„åˆ†éš”ç¬¦
        basename = os.path.basename(filepath)
        filename_no_ext = os.path.splitext(basename)[0]

        # æ ¹æ®æ–‡ä»¶ååŒ¹é…
        if basename == 'models.py' or '/models/' in filepath or filename_no_ext.endswith('_model'):
            categories["æ¨¡å‹å®šä¹‰"].append(file)
        elif basename == 'views.py' or '/views/' in filepath or 'controller' in filename_no_ext.lower():
            if 'api' in filepath.lower() or 'rest' in filepath.lower():
                categories["APIæ¥å£"].append(file)
            else:
                categories["è§†å›¾æ§åˆ¶"].append(file)
        elif basename == 'urls.py' or '/urls/' in filepath or 'route' in filename_no_ext.lower():
            categories["URLé…ç½®"].append(file)
        elif basename == 'serializers.py' or '/serializers/' in filepath or filename_no_ext.endswith('_serializer'):
            categories["åºåˆ—åŒ–å™¨"].append(file)
        elif '/migrations/' in filepath or filename_no_ext.startswith('migrate_'):
            categories["è¿ç§»æ–‡ä»¶"].append(file)
        # ä»»åŠ¡å¤„ç†ç›¸å…³
        elif basename in ['tasks.py', 'jobs.py'] or '/tasks/' in filepath or '/jobs/' in filepath or 'celery' in filepath.lower():
            categories["ä»»åŠ¡é˜Ÿåˆ—"].append(file)
        # æ•°æ®å¤„ç†ç›¸å…³
        elif any(term in filepath.lower() for term in ['data', 'processor', 'analyzer', 'parser']):
            categories["æ•°æ®å¤„ç†"].append(file)
        # å·¥å…·ç±»
        elif basename in ['utils.py', 'helpers.py', 'tools.py'] or '/utils/' in filepath or '/helpers/' in filepath:
            categories["å·¥å…·å‡½æ•°"].append(file)
        # æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
        elif any(term in filepath.lower() for term in ['/core/', '/business/', '/domain/', '/service/']):
            categories["æ ¸å¿ƒé€»è¾‘"].append(file)
        # é…ç½®ç®¡ç†
        elif basename in ['settings.py', 'config.py', 'conf.py'] or '/config/' in filepath or '/settings/' in filepath:
            categories["é…ç½®ç®¡ç†"].append(file)
        # å®‰å…¨è®¤è¯
        elif any(term in filepath.lower() for term in ['auth', 'permission', 'security', 'acl']):
            categories["å®‰å…¨è®¤è¯"].append(file)
        # ä¸­é—´ä»¶
        elif 'middleware' in filepath.lower() or basename == 'middlewares.py':
            categories["ä¸­é—´ä»¶"].append(file)
        # å•å…ƒæµ‹è¯•
        elif basename == 'tests.py' or '/tests/' in filepath or filename_no_ext.startswith('test_'):
            categories["å•å…ƒæµ‹è¯•"].append(file)
        # æ–‡æ¡£å·¥å…·
        elif 'doc' in filepath.lower() or 'sphinx' in filepath.lower():
            categories["æ–‡æ¡£å·¥å…·"].append(file)
        # APIè§†å›¾å•ç‹¬åˆ†ç±»
        elif 'api.py' in filepath or '/api/' in filepath:
            categories["APIæ¥å£"].append(file)
        # é»˜è®¤åˆ†ç±»
        else:
            # æ£€æŸ¥æ–‡ä»¶å†…å®¹æ¥ç¡®å®šç±»åˆ«
            try:
                with open(file, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read().lower()

                # æ ¹æ®å†…å®¹ç‰¹å¾è¿›è¡Œåˆ†ç±»
                if 'class meta:' in content and ('objects' in content or 'fields' in content):
                    categories["æ¨¡å‹å®šä¹‰"].append(file)
                elif '@api_view' in content or 'viewset' in content or 'apiview' in content:
                    categories["APIæ¥å£"].append(file)
                elif 'urlpatterns' in content or 'path(' in content or 're_path(' in content:
                    categories["URLé…ç½®"].append(file)
                elif 'serializer' in content and 'class meta:' in content:
                    categories["åºåˆ—åŒ–å™¨"].append(file)
                elif '@task' in content or 'celery' in content:
                    categories["ä»»åŠ¡é˜Ÿåˆ—"].append(file)
                elif 'test' in content and ('unittest' in content or 'pytest' in content or 'assertequal' in content):
                    categories["å•å…ƒæµ‹è¯•"].append(file)
                else:
                    categories["å…¶ä»–"].append(file)
            except Exception:
                categories["å…¶ä»–"].append(file)

    # åªè¿”å›éç©ºç±»åˆ«
    return {k: v for k, v in categories.items() if v}


def guess_commit_type(status_groups, module_changes, file_types):
    """çŒœæµ‹æäº¤ç±»å‹"""
    # æ£€æŸ¥æ˜¯å¦æœ‰æ–°å¢æ–‡ä»¶
    if status_groups['A'] and not status_groups['M'] and not status_groups['D']:
        if any('__init__.py' in f for f in status_groups['A']) and any('models.py' in f for f in status_groups['A']):
            return "feat", "æ–°å¢åŠŸèƒ½æ¨¡å—"
        return "feat", "æ–°åŠŸèƒ½"

    # æ£€æŸ¥æ˜¯å¦ä»…ä¿®æ”¹æ–‡æ¡£
    if all(f.endswith(('.md', '.txt', '.rst')) for f in status_groups['M'] + status_groups['A']):
        return "docs", "æ–‡æ¡£æ›´æ–°"

    # æ£€æŸ¥æ˜¯å¦ä¸ºé…ç½®å˜æ›´
    if all(f.endswith(('.json', '.ini', '.yml', '.yaml', '.config')) for f in status_groups['M'] + status_groups['A']):
        return "config", "é…ç½®å˜æ›´"

    # æ£€æŸ¥æ˜¯å¦åŒ…å«è¿ç§»æ–‡ä»¶
    has_migrations = any('/migrations/' in f for f in status_groups['A'] + status_groups['M'])
    if has_migrations:
        return "db", "æ•°æ®åº“å˜æ›´"

    # æ£€æŸ¥æ˜¯å¦ä¸ºæµ‹è¯•ç›¸å…³å˜æ›´
    if all('test' in f.lower() or '/tests/' in f for f in status_groups['M'] + status_groups['A']):
        return "test", "æµ‹è¯•ç›¸å…³"

    # é»˜è®¤ä¸ºç‰¹æ€§
    return "feat", "åŠŸèƒ½å®ç°"


def determine_scope(module_changes):
    """ç¡®å®šå˜æ›´çš„èŒƒå›´ï¼ˆä½œç”¨åŸŸï¼‰"""
    # å¦‚æœåªæœ‰ä¸€ä¸ªæ¨¡å—ï¼Œä½¿ç”¨è¯¥æ¨¡å—å
    if len(module_changes) == 1:
        scope = next(iter(module_changes.keys()))
        if scope == 'other':
            return None
        return scope.split('/')[-1] if '/' in scope else scope

    # å¦‚æœå˜æ›´æ¶‰åŠå¤šä¸ªåº”ç”¨æ¨¡å—
    app_modules = [m for m in module_changes if m.startswith('apps/')]
    if len(app_modules) == 1:
        return app_modules[0].split('/')[-1]

    # æ— æ³•ç¡®å®šå•ä¸€èŒƒå›´
    return None


def analyze_code_content(filepath, status):
    """åˆ†æä»£ç æ–‡ä»¶å†…å®¹ï¼Œæå–æ›´æœ‰ä»·å€¼çš„ä¿¡æ¯"""
    # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–åˆ é™¤äº†ï¼Œæ— æ³•åˆ†æå†…å®¹
    if status == 'D' or not os.path.exists(filepath):
        return None

    insights = []

    try:
        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()

        # åˆ†æç±»å®šä¹‰
        class_pattern = r'class\s+(\w+)'
        classes = re.findall(class_pattern, content)

        # åˆ†æå‡½æ•°/æ–¹æ³•å®šä¹‰
        func_pattern = r'def\s+(\w+)'
        functions = re.findall(func_pattern, content)

        # æ£€æŸ¥æ˜¯å¦æœ‰APIç›¸å…³çš„è£…é¥°å™¨
        has_api_endpoints = any(decorator in content for decorator in
                               ['@api_view', '@action', '@router', '@app.route'])

        # æ£€æŸ¥æ˜¯å¦æœ‰å¼‚æ­¥å‡½æ•°
        has_async = 'async def' in content

        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ•°æ®åº“æŸ¥è¯¢
        has_db_queries = any(query in content for query in
                           ['SELECT ', 'INSERT ', 'UPDATE ', 'DELETE ', 'objects.filter',
                            'objects.get', 'objects.create', 'objects.update'])

        # æ£€æŸ¥æ˜¯å¦æœ‰ç®—æ³•ä¼˜åŒ–ç›¸å…³å…³é”®è¯
        has_algorithm = any(kw in content.lower() for kw in
                          ['algorithm', 'optimization', 'cache', 'performance',
                           'efficient', 'complexity', 'optimize'])

        # åˆ¤æ–­æ–‡ä»¶çš„ä¸»è¦åŠŸèƒ½
        if classes and len(classes) > 0:
            # æ‰¾å‡ºæœ€æœ‰æ„ä¹‰çš„ç±»å
            main_classes = [c for c in classes if not (c.endswith('Test') or c.startswith('Test'))]
            if main_classes:
                insights.append(f"å®šä¹‰äº†{len(main_classes)}ä¸ªç±»ï¼š{', '.join(main_classes[:2])}")

        if has_api_endpoints:
            insights.append("åŒ…å«APIæ¥å£å®šä¹‰")

        if has_async:
            insights.append("å®ç°å¼‚æ­¥å¤„ç†")

        if has_db_queries:
            insights.append("åŒ…å«æ•°æ®åº“æ“ä½œ")

        if has_algorithm:
            insights.append("ä¼˜åŒ–ç®—æ³•å®ç°")

        # æå–TODOå’ŒFIXMEæ³¨é‡Š
        todo_pattern = r'#\s*(TODO|FIXME):\s*(.*)'
        todos = re.findall(todo_pattern, content)
        if todos:
            insights.append(f"è§£å†³äº†{len(todos)}ä¸ªTODO/FIXMEé¡¹")

    except Exception as e:
        # æ–‡ä»¶è¯»å–å¤±è´¥ï¼Œè¿”å›åŸºæœ¬ä¿¡æ¯
        return []

    return insights

def analyze_code_changes(changes):
    """æ·±å…¥åˆ†æä»£ç å˜æ›´ï¼Œå°è¯•æå–æ›´æœ‰æ„ä¹‰çš„å˜æ›´æ¦‚è¿°"""
    feature_additions = []
    bug_fixes = []
    refactorings = []
    improvements = []
    model_changes = []
    api_changes = []
    performance_improvements = []
    security_enhancements = []
    config_changes = []

    # æ‰©å±•ç‰¹æ®Šæ–‡ä»¶åˆ—è¡¨
    special_files = {
        'cleanup_large_files.bat': 'æ¸…ç†å¤§æ–‡ä»¶æ‰¹å¤„ç†è„šæœ¬',
        'generate_commit_message.py': 'æäº¤ä¿¡æ¯ç”Ÿæˆå·¥å…·',
        'restore_missing_tables.py': 'æ¢å¤ç¼ºå¤±æ•°æ®è¡¨å·¥å…·',
        '.gitignore': 'Gitå¿½ç•¥é…ç½®',
        'requirements.txt': 'é¡¹ç›®ä¾èµ–',
        'setup.py': 'é¡¹ç›®å®‰è£…é…ç½®',
        'Dockerfile': 'å®¹å™¨åŒ–é…ç½®',
        'docker-compose.yml': 'å®¹å™¨ç¼–æ’é…ç½®',
        'settings.py': 'é¡¹ç›®è®¾ç½®',
        'urls.py': 'ä¸»URLé…ç½®',
        'wsgi.py': 'WSGIåº”ç”¨é…ç½®',
        'asgi.py': 'ASGIåº”ç”¨é…ç½®'
    }

    # æ¨¡å—ä¸åŠŸèƒ½æ˜ å°„
    module_features = {
        'tasks': 'ä»»åŠ¡ç®¡ç†',
        'users': 'ç”¨æˆ·ç³»ç»Ÿ',
        'auth': 'è®¤è¯æˆæƒ',
        'data_source': 'æ•°æ®æº',
        'reports': 'æŠ¥è¡¨ç”Ÿæˆ',
        'dashboard': 'ä»ªè¡¨ç›˜',
        'notifications': 'é€šçŸ¥ç³»ç»Ÿ',
        'api': 'APIæ¥å£',
        'core': 'æ ¸å¿ƒåŠŸèƒ½',
        'utils': 'å·¥å…·å‡½æ•°',
        'helpers': 'åŠ©æ‰‹å‡½æ•°',
        'middlewares': 'ä¸­é—´ä»¶',
        'tests': 'æµ‹è¯•ç”¨ä¾‹'
    }

    # æ£€æµ‹é‡è¦ç›®å½•çš„å˜æ›´
    important_dirs = {
        'migrations': 'æ•°æ®åº“è¿ç§»',
        'tests': 'æµ‹è¯•å¥—ä»¶',
        'static': 'é™æ€èµ„æº',
        'templates': 'æ¨¡æ¿æ–‡ä»¶',
        'docs': 'æ–‡æ¡£'
    }

    # åˆ†ææ–‡ä»¶å˜æ›´
    python_files_count = 0
    frontend_files_count = 0
    template_files_count = 0
    static_files_count = 0
    config_files_count = 0

    # åˆ†ææ–‡ä»¶ç±»å‹ç»Ÿè®¡
    for status, filepath in changes:
        ext = os.path.splitext(filepath)[1].lower()

        # åˆ†ç±»æ–‡ä»¶
        if ext in ['.py']:
            python_files_count += 1
        elif ext in ['.js', '.ts', '.jsx', '.tsx', '.vue']:
            frontend_files_count += 1
        elif ext in ['.html', '.htm', '.jinja', '.jinja2', '.tpl']:
            template_files_count += 1
        elif ext in ['.css', '.scss', '.less', '.jpg', '.png', '.svg']:
            static_files_count += 1
        elif ext in ['.json', '.yml', '.yaml', '.toml', '.ini', '.conf']:
            config_files_count += 1

    # æ£€æŸ¥ç‰¹æ®Šæ–‡ä»¶å˜æ›´
    for status, filepath in changes:
        basename = os.path.basename(filepath)

        # ç‰¹æ®Šæ–‡ä»¶æ£€æŸ¥
        if basename in special_files:
            if status == 'A':
                improvements.append(f"æ–°å¢{special_files[basename]}")
            elif status == 'M':
                improvements.append(f"æ›´æ–°{special_files[basename]}")

        # æ£€æŸ¥æ˜¯å¦æ˜¯å®‰å…¨ç›¸å…³æ–‡ä»¶
        if any(security_term in filepath.lower() for security_term in
              ['security', 'auth', 'permission', 'acl', 'access', 'role']):
            security_enhancements.append("å®‰å…¨æ§åˆ¶")

        # é‡è¦é…ç½®æ–‡ä»¶
        if basename in ['settings.py', 'config.py', '.env']:
            config_changes.append("æ ¸å¿ƒé…ç½®")

    # æ™ºèƒ½åˆ†ææ¨¡å—å˜æ›´
    analyzed_modules = set()
    for status, filepath in changes:
        # æå–æ¨¡å—å
        path_parts = os.path.normpath(filepath).split(os.sep)

        # å°è¯•ä»è·¯å¾„ä¸­è¯†åˆ«æ¨¡å—
        potential_modules = []
        # ä»è·¯å¾„ä¸­æŸ¥æ‰¾å¯èƒ½çš„æ¨¡å—å
        for part in path_parts:
            if part in module_features and part not in analyzed_modules:
                potential_modules.append(part)
                analyzed_modules.add(part)

        # å¦‚æœæ‰¾åˆ°æ¨¡å—ï¼Œåˆ†æå…¶åŠŸèƒ½
        for module in potential_modules:
            feature_name = module_features.get(module)
            # æ ¹æ®æ–‡ä»¶å˜æ›´ç±»å‹ç¡®å®šæ˜¯æ–°å¢åŠŸèƒ½è¿˜æ˜¯æ”¹è¿›
            if status == 'A':
                if '/models.py' in filepath or '\\models.py' in filepath:
                    model_changes.append(f"{feature_name}æ¨¡å‹")
                elif '/views.py' in filepath or '/api.py' in filepath or '\\views.py' in filepath:
                    api_changes.append(f"{feature_name}æ¥å£")
                else:
                    feature_additions.append(feature_name)
            elif status == 'M':
                # å°è¯•é€šè¿‡ä»£ç å†…å®¹åˆ†æè·å–æ›´å¤šä¿¡æ¯
                insights = analyze_code_content(filepath, status)
                if insights:
                    # æ ¹æ®ä»£ç åˆ†æç»“æœæ·»åŠ åˆ°ç›¸åº”ç±»åˆ«
                    if any("ä¼˜åŒ–" in insight for insight in insights):
                        performance_improvements.append(f"{feature_name}æ€§èƒ½")
                    elif any("API" in insight for insight in insights):
                        api_changes.append(f"{feature_name}æ¥å£")
                    else:
                        improvements.append(f"{feature_name}åŠŸèƒ½")
                else:
                    improvements.append(feature_name)

    # æ›´æ·±å…¥åˆ†æPythonæ–‡ä»¶
    for status, filepath in changes:
        # è·³è¿‡éPythonæ–‡ä»¶
        if not filepath.endswith('.py'):
            continue

        # æ–°å¢æ–‡ä»¶åˆ†æ
        if status == 'A':
            basename = os.path.basename(filepath)
            name_without_ext = os.path.splitext(basename)[0]

            # ä»¥ä¸‹åˆ†æé€‚ç”¨äºå°šæœªé€šè¿‡æ¨¡å—è¯†åˆ«çš„æ–‡ä»¶
            if 'test' in name_without_ext.lower():
                # æµ‹è¯•æ–‡ä»¶
                improvements.append("è‡ªåŠ¨åŒ–æµ‹è¯•")
            elif any(fix_term in name_without_ext.lower() for fix_term in ['fix', 'bug', 'issue', 'solve']):
                # ä¿®å¤ç±»
                bug_fixes.append(f"{name_without_ext.replace('_', ' ')}é—®é¢˜")
            elif any(util_term in name_without_ext.lower() for util_term in ['util', 'helper', 'tool']):
                # å·¥å…·ç±»
                improvements.append(f"{name_without_ext.replace('_', ' ')}å·¥å…·")
            elif any(perf_term in name_without_ext.lower() for perf_term in ['perf', 'optim', 'fast', 'cache']):
                # æ€§èƒ½ä¼˜åŒ–
                performance_improvements.append(f"{name_without_ext.replace('_', ' ')}æ€§èƒ½")

        # æ–‡ä»¶å†…å®¹åˆ†æï¼Œé€‚ç”¨äºä¿®æ”¹æ–‡ä»¶
        if status == 'M':
            insights = analyze_code_content(filepath, status)

            # æ ¹æ®å†…å®¹åˆ†æå°†æ›´æ”¹åˆ†ç±»
            if insights:
                if any("API" in i for i in insights):
                    module_name = os.path.basename(os.path.dirname(filepath))
                    api_changes.append(f"{module_name}æ¥å£")
                if any("æ•°æ®åº“" in i for i in insights):
                    module_name = os.path.basename(os.path.dirname(filepath))
                    model_changes.append(f"{module_name}æ•°æ®åº“æ“ä½œ")
                if any("ä¼˜åŒ–" in i for i in insights):
                    performance_improvements.append("ä»£ç ä¼˜åŒ–")

    # æ£€æŸ¥æ˜¯å¦é…ç½®äº†æµæ°´çº¿
    if any('jenkins' in filepath.lower() or 'ci' in filepath.lower() or '.github/workflows' in filepath for _, filepath in changes):
        improvements.append("CI/CDæµæ°´çº¿é…ç½®")

    # æ£€æŸ¥æ–‡æ¡£æ›´æ–°
    doc_changes = [filepath for status, filepath in changes if filepath.endswith(('.md', '.rst', '.txt'))
                  and status in ['A', 'M']]
    if doc_changes:
        if any('readme' in filepath.lower() for filepath in doc_changes):
            improvements.append("READMEæ–‡æ¡£")
        else:
            improvements.append("é¡¹ç›®æ–‡æ¡£")

    # é™æ€ç±»å‹æ£€æŸ¥æ›´æ–°
    if any(filepath.endswith(('mypy.ini', '.pyi', 'typing.py')) for _, filepath in changes):
        improvements.append("ç±»å‹å®‰å…¨")

    # æ£€æŸ¥å¤§æ–‡ä»¶å¤„ç†
    if any('gitignore' in filepath.lower() or 'cleanup' in filepath.lower() for _, filepath in changes):
        improvements.append("Gitä»“åº“ç»´æŠ¤")

    # å¦‚æœæœ‰migrationsæ–‡ä»¶ï¼Œç‰¹åˆ«æ ‡æ³¨æ•°æ®åº“æ›´æ”¹
    has_migrations = any('migrations' in filepath for _, filepath in changes)
    if has_migrations:
        model_changes.insert(0, "æ•°æ®åº“ç»“æ„")

    # ç¡®ä¿æ‰€æœ‰åˆ—è¡¨ä¸­çš„å…ƒç´ éƒ½æ˜¯å”¯ä¸€çš„
    return {
        'features': list(set(feature_additions)),
        'bugfixes': list(set(bug_fixes)),
        'refactorings': list(set(refactorings)),
        'improvements': list(set(improvements)),
        'model_changes': list(set(model_changes)),
        'api_changes': list(set(api_changes)),
        'performance_improvements': list(set(performance_improvements)),
        'security_enhancements': list(set(security_enhancements)),
        'config_changes': list(set(config_changes))
    }

def generate_value_summary(changes_analysis):
    """æ ¹æ®åˆ†æç»“æœç”Ÿæˆä»·å€¼é©±åŠ¨çš„æäº¤æ¦‚è¿°"""
    summary_points = []

    # å¤„ç†ç‰¹æ€§æ·»åŠ  - å¼ºè°ƒä¸šåŠ¡ä»·å€¼
    if changes_analysis['features']:
        if len(changes_analysis['features']) == 1:
            feature = changes_analysis['features'][0]
            summary_points.append(f"å®ç°{feature}åŠŸèƒ½ï¼Œæå‡ç”¨æˆ·ä½“éªŒ")
        elif len(changes_analysis['features']) > 0:
            features_text = ', '.join(changes_analysis['features'][:3])
            if len(changes_analysis['features']) > 3:
                extra = f"ç­‰å…±{len(changes_analysis['features'])}é¡¹"
            else:
                extra = ""
            summary_points.append(f"å®ç°å¤šé¡¹æ ¸å¿ƒåŠŸèƒ½ï¼š{features_text}{extra}ï¼Œä¸°å¯Œç³»ç»Ÿåº”ç”¨åœºæ™¯")

    # å¤„ç†APIå˜æ›´ - å¼ºè°ƒé›†æˆä»·å€¼
    if changes_analysis['api_changes']:
        if len(changes_analysis['api_changes']) == 1:
            api = changes_analysis['api_changes'][0]
            summary_points.append(f"è®¾è®¡{api}ï¼Œä¸ºå‰ç«¯æä¾›ç¨³å®šæ•°æ®æ¥å£")
        elif len(changes_analysis['api_changes']) <= 3:
            apis_text = ', '.join(changes_analysis['api_changes'])
            summary_points.append(f"ä¼˜åŒ–ç³»ç»Ÿæ¥å£å±‚ï¼š{apis_text}ï¼Œæå‡æ•°æ®äº¤äº’æ•ˆç‡")
        else:
            summary_points.append(f"é‡æ„APIæ¶æ„ï¼ŒåŒ…å«{len(changes_analysis['api_changes'])}ä¸ªæ¥å£ç‚¹ï¼Œå¢å¼ºç³»ç»Ÿå¯æ‰©å±•æ€§")

    # å¤„ç†æ¨¡å‹å˜æ›´ - å¼ºè°ƒæ•°æ®ä»·å€¼
    if changes_analysis['model_changes']:
        if len(changes_analysis['model_changes']) == 1:
            model = changes_analysis['model_changes'][0]
            summary_points.append(f"å®Œå–„{model}ï¼Œç¡®ä¿æ•°æ®ç»“æ„åˆç†æ€§")
        elif len(changes_analysis['model_changes']) <= 3:
            models_text = ', '.join(changes_analysis['model_changes'])
            summary_points.append(f"ä¼˜åŒ–æ•°æ®æ¨¡å‹ï¼š{models_text}ï¼Œæé«˜æ•°æ®å®Œæ•´æ€§å’ŒæŸ¥è¯¢æ•ˆç‡")
        else:
            summary_points.append(f"é‡æ„{len(changes_analysis['model_changes'])}ä¸ªæ•°æ®æ¨¡å‹ï¼Œå»ºç«‹æ›´åˆç†çš„æ•°æ®å…³ç³»")

    # å¤„ç†æ€§èƒ½æ”¹è¿› - å¼ºè°ƒç”¨æˆ·ä½“éªŒ
    if changes_analysis.get('performance_improvements', []):
        perfs = changes_analysis['performance_improvements']
        if perfs:
            if len(perfs) == 1:
                summary_points.append(f"ä¼˜åŒ–{perfs[0]}ï¼Œæå‡ç³»ç»Ÿå“åº”é€Ÿåº¦")
            else:
                summary_points.append(f"å…¨é¢æ€§èƒ½ä¼˜åŒ–ï¼šåŒ…æ‹¬{', '.join(perfs[:2])}ç­‰æ–¹é¢ï¼Œæ˜¾è‘—æ”¹å–„ç”¨æˆ·ä½“éªŒ")

    # å¤„ç†å®‰å…¨å¢å¼º - å¼ºè°ƒç³»ç»Ÿç¨³å®šæ€§
    if changes_analysis.get('security_enhancements', []):
        if changes_analysis['security_enhancements']:
            summary_points.append("åŠ å¼ºç³»ç»Ÿå®‰å…¨æ€§ï¼Œé˜²æ­¢æ½œåœ¨æ•°æ®æ³„éœ²é£é™©")

    # å¤„ç†é…ç½®å˜æ›´ - å¼ºè°ƒç³»ç»Ÿç®¡ç†ä»·å€¼
    if changes_analysis.get('config_changes', []):
        if changes_analysis['config_changes']:
            summary_points.append("ä¼˜åŒ–ç³»ç»Ÿé…ç½®ï¼Œæå‡ç¯å¢ƒé€‚åº”æ€§å’Œéƒ¨ç½²ä¾¿æ·åº¦")

    # å¤„ç†æ”¹è¿› - å¼ºè°ƒè´¨é‡æå‡
    if changes_analysis['improvements']:
        if len(changes_analysis['improvements']) == 1:
            improvement = changes_analysis['improvements'][0]
            summary_points.append(f"æ”¹è¿›{improvement}ï¼Œæå‡ä»£ç å¯ç»´æŠ¤æ€§")
        elif len(changes_analysis['improvements']) > 0:
            imp_text = ', '.join(changes_analysis['improvements'][:2])
            summary_points.append(f"æ”¹è¿›ç³»ç»Ÿå·¥å…·å’ŒåŸºç¡€è®¾æ–½ï¼š{imp_text}ç­‰ï¼Œå¢å¼ºå¼€å‘æ•ˆç‡å’Œä»£ç è´¨é‡")

    # å¤„ç†Bugä¿®å¤ - å¼ºè°ƒç¨³å®šæ€§ä»·å€¼
    if changes_analysis['bugfixes']:
        if len(changes_analysis['bugfixes']) == 1:
            bug = changes_analysis['bugfixes'][0]
            summary_points.append(f"ä¿®å¤{bug}ï¼Œæ¶ˆé™¤ç³»ç»Ÿä¸ç¨³å®šå› ç´ ")
        elif len(changes_analysis['bugfixes']) > 0:
            bugs_text = ', '.join(changes_analysis['bugfixes'][:2])
            if len(changes_analysis['bugfixes']) > 2:
                extra = "ç­‰å¤šå¤„"
            else:
                extra = ""
            summary_points.append(f"ä¿®å¤{bugs_text}{extra}é—®é¢˜ï¼Œå¢å¼ºç³»ç»Ÿç¨³å®šæ€§")

    # å¤„ç†é‡æ„ - å¼ºè°ƒé•¿æœŸç»´æŠ¤ä»·å€¼
    if changes_analysis['refactorings']:
        if changes_analysis['refactorings']:
            summary_points.append("é‡æ„ä»£ç ç»“æ„ï¼Œæé«˜ç³»ç»Ÿå¯ç»´æŠ¤æ€§å’Œæ‰©å±•æ€§")

    # å¤„ç†å¤§æ–‡ä»¶æ¸…ç†
    has_git_improvements = False
    for imp in changes_analysis['improvements']:
        if 'Git' in imp or 'ä»“åº“' in imp or 'å¤§æ–‡ä»¶' in imp:
            has_git_improvements = True
            break

    if has_git_improvements:
        summary_points.append("ä¼˜åŒ–Gitä»“åº“ç»“æ„ï¼Œè§£å†³å¤§æ–‡ä»¶é—®é¢˜ï¼Œç¡®ä¿ä»£ç é¡ºåˆ©æ¨é€å’Œå…±äº«")

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç‰¹å®šå˜æ›´ç‚¹ï¼Œç”Ÿæˆä¸€ä¸ªåŸºäºä¸šåŠ¡ä»·å€¼çš„é€šç”¨æè¿°
    if not summary_points:
        return "æ›´æ–°ç³»ç»Ÿä»£ç å’Œé…ç½®ï¼Œä¼˜åŒ–æ•´ä½“æ¶æ„å¹¶æé«˜è¿è¡Œæ•ˆç‡"    # å°†æ‰€æœ‰ç‚¹è¿æ¥èµ·æ¥ï¼Œä½†åˆ†è¡Œå¤„ç†ä»¥é¿å…å¤ªé•¿çš„è¡Œ

    # è¿‡æ»¤ç©ºå€¼
    valid_points = [p for p in summary_points if p.strip()]

    # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„ç‚¹ï¼Œè¿”å›é»˜è®¤æ¶ˆæ¯
    if not valid_points:
        return "æ›´æ–°ç³»ç»Ÿä»£ç å’Œé…ç½®ï¼Œä¼˜åŒ–æ•´ä½“æ¶æ„å¹¶æé«˜è¿è¡Œæ•ˆç‡"

    # æ ¼å¼åŒ–æ¯ä¸ªç‚¹ï¼Œç¡®ä¿ä¸ä¼šå¤ªé•¿
    formatted_points = [format_value_point(point, 60) for point in valid_points]

    # ç»„åˆæˆå¤šè¡Œæ–‡æœ¬ï¼Œæ¯è¡Œä¸è¶…è¿‡80ä¸ªå­—ç¬¦
    value_lines = []
    current_line = ""
    max_line_length = 70  # æœ€å¤§è¡Œé•¿åº¦

    for point in formatted_points:
        # å¦‚æœå½“å‰è¡Œä¸ºç©ºï¼Œç›´æ¥æ·»åŠ 
        if not current_line:
            current_line = point
        # å¦‚æœæ·»åŠ åä¸ä¼šå¤ªé•¿ï¼Œåˆ™æ·»åŠ åˆ°å½“å‰è¡Œ
        elif len(current_line) + len(point) + 2 <= max_line_length:  # +2 for the separator
            current_line += f"ï¼›{point}"
        # å¦åˆ™å¼€å§‹æ–°è¡Œ
        else:
            if not current_line.endswith("ã€‚"):
                current_line += "ã€‚"
            value_lines.append(current_line)
            current_line = point

    # æ·»åŠ æœ€åä¸€è¡Œ
    if current_line:
        if not current_line.endswith("ã€‚"):
            current_line += "ã€‚"
        value_lines.append(current_line)

    return "\n".join(value_lines)

def determine_commit_type_from_changes(changes_analysis):
    """ä»å˜æ›´åˆ†æç»“æœç¡®å®šæ›´å‡†ç¡®çš„æäº¤ç±»å‹"""
    # ç¡®å®šæäº¤ç±»å‹çš„ä¼˜å…ˆçº§
    if changes_analysis.get('security_enhancements'):
        return 'security', 'å¢å¼ºç³»ç»Ÿå®‰å…¨æ€§'

    if changes_analysis.get('bugfixes'):
        return 'fix', 'ä¿®å¤ç³»ç»Ÿé—®é¢˜'

    if changes_analysis.get('features'):
        return 'feat', 'æ–°å¢åŠŸèƒ½ç‰¹æ€§'

    if changes_analysis.get('api_changes'):
        return 'api', 'ä¼˜åŒ–APIæ¥å£'

    if changes_analysis.get('model_changes'):
        return 'model', 'æ›´æ–°æ•°æ®æ¨¡å‹'

    if changes_analysis.get('performance_improvements'):
        return 'perf', 'æ€§èƒ½ä¼˜åŒ–'

    if changes_analysis.get('refactorings'):
        return 'refactor', 'é‡æ„ä»£ç ç»“æ„'

    if changes_analysis.get('config_changes'):
        return 'config', 'æ›´æ–°ç³»ç»Ÿé…ç½®'

    # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æ¡£æ”¹è¿›
    for improvement in changes_analysis.get('improvements', []):
        if 'æ–‡æ¡£' in improvement:
            return 'docs', 'æ›´æ–°é¡¹ç›®æ–‡æ¡£'

    # æ£€æŸ¥Gitä»“åº“ç»´æŠ¤
    for improvement in changes_analysis.get('improvements', []):
        if 'Git' in improvement or 'ä»“åº“' in improvement:
            return 'chore', 'ä»“åº“ç»´æŠ¤'

    # é»˜è®¤ä¸ºæ‚åŠ¡æˆ–æ”¹è¿›
    return 'chore', 'ç³»ç»Ÿæ”¹è¿›'

def extract_main_feature(changes_analysis):
    """æå–å˜æ›´ä¸­æœ€ä¸»è¦çš„åŠŸèƒ½ï¼Œç”¨äºæäº¤ä¿¡æ¯æ ‡é¢˜"""
    # æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥å„ç±»å˜æ›´
    if changes_analysis.get('features'):
        main_feature = changes_analysis['features'][0]
        return f"å®ç°{main_feature}åŠŸèƒ½"

    if changes_analysis.get('api_changes'):
        main_api = changes_analysis['api_changes'][0]
        return f"ä¼˜åŒ–{main_api}"

    if changes_analysis.get('model_changes'):
        main_model = changes_analysis['model_changes'][0]
        return f"æ”¹è¿›{main_model}"

    if changes_analysis.get('bugfixes'):
        main_bug = changes_analysis['bugfixes'][0]
        return f"ä¿®å¤{main_bug}"

    if changes_analysis.get('performance_improvements'):
        main_perf = changes_analysis['performance_improvements'][0]
        return f"ä¼˜åŒ–{main_perf}"

    if changes_analysis.get('security_enhancements'):
        return "å¢å¼ºç³»ç»Ÿå®‰å…¨æ€§"

    if changes_analysis.get('improvements'):
        main_improvement = changes_analysis['improvements'][0]
        return f"æ”¹è¿›{main_improvement}"

    # é»˜è®¤æè¿°
    return "æ›´æ–°ç³»ç»Ÿç»„ä»¶"

def generate_commit_message(changes):
    """ç”Ÿæˆæäº¤ä¿¡æ¯ï¼Œæ³¨é‡çªå‡ºä»£ç å˜æ›´çš„ä¸šåŠ¡ä»·å€¼"""
    if not changes:
        return "chore: æ— æ–‡ä»¶å˜æ›´"

    # åŸºç¡€åˆ†æ
    status_groups, module_changes, file_types = analyze_changes(changes)

    # æ·±å…¥åˆ†æä»£ç å˜æ›´
    changes_analysis = analyze_code_changes(changes)

    # ç”Ÿæˆä»·å€¼é©±åŠ¨çš„æ¦‚è¿°
    value_summary = generate_value_summary(changes_analysis)

    # ç¡®å®šæäº¤ç±»å‹å’Œä¸»è¦åŠŸèƒ½æè¿°
    commit_type, _ = determine_commit_type_from_changes(changes_analysis)

    # ä»å˜æ›´åˆ†æä¸­æå–ä¸»è¦åŠŸèƒ½ä½œä¸ºæè¿°
    commit_desc = extract_main_feature(changes_analysis)

    # ç¡®å®šèŒƒå›´ï¼ˆæ¨¡å—ï¼‰
    scope = determine_scope(module_changes)

    # æ£€æŸ¥å¤§æ–‡ä»¶é—®é¢˜
    has_large_file_fix = any('Gitä»“åº“' in imp or 'å¤§æ–‡ä»¶' in imp for imp in changes_analysis.get('improvements', []))
    if has_large_file_fix:
        # å¦‚æœæ˜¯å¤„ç†å¤§æ–‡ä»¶é—®é¢˜ï¼Œè¦†ç›–æäº¤ç±»å‹å’Œæè¿°
        commit_type = 'fix'
        commit_desc = 'è§£å†³å¤§æ–‡ä»¶æ¨é€é—®é¢˜'
        scope = 'repo'

    # ç”Ÿæˆæäº¤æ ‡é¢˜
    if scope:
        title = f"{commit_type}({scope}): {commit_desc}"
    else:
        title = f"{commit_type}: {commit_desc}"

    # ç”Ÿæˆå˜æ›´ç»Ÿè®¡æ¦‚è¿°
    summary = get_change_summary(status_groups)

    # ç”ŸæˆæŒ‰æ¨¡å—çš„è¯¦ç»†å˜æ›´ä¿¡æ¯
    details = get_module_details(module_changes)

    # æ£€æŸ¥æ˜¯å¦æœ‰é‡è¦çš„æ–‡ä»¶å˜æ›´éœ€è¦ç‰¹åˆ«çªå‡º
    important_changes = []

    # æ£€æŸ¥.gitignoreå˜æ›´
    if any(filepath.endswith('.gitignore') for _, filepath in changes):
        important_changes.append("* æ›´æ–°äº†.gitignoreé…ç½®ï¼Œä¼˜åŒ–å¯¹å¤§æ–‡ä»¶çš„å¤„ç†")

    # æ£€æŸ¥æ¸…ç†è„šæœ¬
    if any('cleanup' in filepath for _, filepath in changes):
        important_changes.append("* æ·»åŠ äº†å¤§æ–‡ä»¶æ¸…ç†è„šæœ¬ï¼Œä¾¿äºç»´æŠ¤Gitä»“åº“")

    # æ£€æŸ¥commit messageç”Ÿæˆå™¨æ”¹è¿›
    if any('generate_commit_message.py' in filepath for _, filepath in changes):
        important_changes.append("* æ”¹è¿›äº†æäº¤ä¿¡æ¯ç”Ÿæˆå·¥å…·ï¼Œæ›´èƒ½åæ˜ ä»£ç å˜æ›´çš„ä»·å€¼")    # ç»„è£…å®Œæ•´çš„æäº¤ä¿¡æ¯
    message_parts = [
        title,
        ""
    ]

    # å¤„ç†ä»·å€¼æ¦‚è¿°éƒ¨åˆ†ï¼ˆå¯èƒ½æ˜¯å¤šè¡Œï¼‰
    for line in value_summary.split('\n'):
        message_parts.append(line)

    # å¦‚æœæœ‰é‡è¦å˜æ›´éœ€è¦çªå‡ºï¼Œæ·»åŠ åˆ°ä¿¡æ¯ä¸­
    if important_changes:
        message_parts.extend([
            "",
            "é‡è¦å˜æ›´ï¼š",
            "\n".join(important_changes)
        ])

    # æ·»åŠ æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯å’Œè¯¦ç»†æ¨¡å—å˜æ›´
    message_parts.extend([
        "",
        summary + "ã€‚",
        "",
        "ä¸»è¦æ”¹åŠ¨:",
        "",
        details
    ])

    return "\n".join(message_parts)


def cleanup_old_files():
    """æ¸…ç†ä¹‹å‰ç”Ÿæˆçš„æ–‡ä»¶"""
    # åˆ é™¤æ—§çš„git_changesæ–‡ä»¶
    for file in os.listdir('.'):
        if file.startswith('git_changes_') and file.endswith('.txt'):
            try:
                os.remove(file)
                print(f"å·²åˆ é™¤æ—§æ–‡ä»¶: {file}")
            except Exception as e:
                print(f"æ— æ³•åˆ é™¤æ–‡ä»¶ {file}: {e}")

    # åˆ é™¤æ—§çš„commit_messageæ–‡ä»¶
    for file in os.listdir('.'):
        if file.startswith('commit_message_') and file.endswith('.txt'):
            try:
                os.remove(file)
                print(f"å·²åˆ é™¤æ—§æ–‡ä»¶: {file}")
            except Exception as e:
                print(f"æ— æ³•åˆ é™¤æ–‡ä»¶ {file}: {e}")


def save_changes_to_file(changes):
    """å°†å˜æ›´ä¿¡æ¯ä¿å­˜åˆ°æ–‡ä»¶"""
    filename = "git_changes.txt"

    with open(filename, 'w', encoding='utf-8') as f:
        f.write("å˜æ›´æ–‡ä»¶åˆ—è¡¨:\n")
        f.write("=" * 40 + "\n")
        for status, filepath in changes:
            f.write(f"{status}\t{filepath}\n")

    return filename


def check_large_files(changes):
    """æ£€æŸ¥æš‚å­˜åŒºä¸­æ˜¯å¦æœ‰è¶…è¿‡ GitHub æ¨èå¤§å°é™åˆ¶çš„æ–‡ä»¶"""
    large_files = []
    warning_files = []
    lfs_suggestion_files = []

    for _, filepath in changes:
        if not os.path.exists(filepath):
            continue

        file_size = os.path.getsize(filepath)
        if file_size > GITHUB_FILE_SIZE_LIMIT:
            large_files.append((filepath, file_size))
        elif file_size > GITHUB_RECOMMENDED_LIMIT:
            warning_files.append((filepath, file_size))
        elif file_size > GITHUB_LFS_SUGGESTION:
            lfs_suggestion_files.append((filepath, file_size))

    return large_files, warning_files, lfs_suggestion_files

def format_value_point(point, max_length=80):
    """æ ¼å¼åŒ–ä»·å€¼ç‚¹ï¼Œç¡®ä¿ä¸è¶…è¿‡æœ€å¤§é•¿åº¦"""
    if len(point) <= max_length:
        return point

    # å¦‚æœè¶…è¿‡é•¿åº¦ï¼Œå°è¯•åœ¨åˆé€‚ä½ç½®æˆªæ–­
    parts = point.split('ï¼Œ')
    if len(parts) >= 2:
        return parts[0] + 'ï¼Œ...'

    return point[:max_length-3] + '...'

def format_file_size(size_in_bytes):
    """å°†å­—èŠ‚å¤§å°è½¬æ¢ä¸ºäººç±»å¯è¯»æ ¼å¼"""
    if size_in_bytes < 1024:
        return f"{size_in_bytes} B"
    elif size_in_bytes < 1024 * 1024:
        return f"{size_in_bytes / 1024:.1f} KB"
    elif size_in_bytes < 1024 * 1024 * 1024:
        return f"{size_in_bytes / (1024 * 1024):.1f} MB"
    else:
        return f"{size_in_bytes / (1024 * 1024 * 1024):.1f} GB"


def check_git_config():
    """æ£€æŸ¥Gité…ç½®ï¼Œç‰¹åˆ«æ˜¯ä¸å¤§æ–‡ä»¶ç›¸å…³çš„é…ç½®"""
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†Git LFS
    lfs_installed = run_git_command("git lfs version")
    is_lfs_enabled = bool(lfs_installed and not lfs_installed.startswith('git: '))

    # æ£€æŸ¥è¿œç¨‹ä»“åº“é™åˆ¶
    remote_url = run_git_command("git config --get remote.origin.url")
    is_github = "github.com" in remote_url
    is_gitlab = "gitlab.com" in remote_url

    return {
        "lfs_enabled": is_lfs_enabled,
        "is_github": is_github,
        "is_gitlab": is_gitlab,
        "remote_url": remote_url
    }

def suggest_fix_for_large_files(large_files, git_config):
    """æ ¹æ®æ£€æµ‹åˆ°çš„å¤§æ–‡ä»¶å’ŒGité…ç½®ï¼Œæä¾›è§£å†³æ–¹æ¡ˆå»ºè®®"""
    if not large_files:
        return []

    suggestions = []

    if not git_config["lfs_enabled"]:
        suggestions.append("1. å®‰è£…å¹¶é…ç½®Git LFSï¼š")
        suggestions.append("   - å®‰è£…LFS: git lfs install")
        suggestions.append("   - è·Ÿè¸ªå¤§æ–‡ä»¶: git lfs track \"*.æ‰©å±•å\"")
        suggestions.append("   - æ·»åŠ .gitattributes: git add .gitattributes")
    else:
        suggestions.append("1. ä¸ºæ£€æµ‹åˆ°çš„å¤§æ–‡ä»¶å¯ç”¨Git LFSè·Ÿè¸ªï¼š")
        extensions = set(os.path.splitext(file)[1] for file, _ in large_files if os.path.splitext(file)[1])
        for ext in extensions:
            suggestions.append(f"   - git lfs track \"*{ext}\"")
        suggestions.append("   - git add .gitattributes")

    suggestions.append("\n2. é‡æ–°æ·»åŠ å¤§æ–‡ä»¶åˆ°æš‚å­˜åŒºï¼š")
    for file, _ in large_files:
        suggestions.append(f"   - git add \"{file}\"")

    suggestions.append("\n3. å¦‚æœä¸éœ€è¦æäº¤è¿™äº›å¤§æ–‡ä»¶ï¼Œä»æš‚å­˜åŒºç§»é™¤ï¼š")
    for file, _ in large_files:
        suggestions.append(f"   - git reset HEAD \"{file}\"")

    suggestions.append("\n4. æˆ–è€…è€ƒè™‘åœ¨.gitignoreä¸­å¿½ç•¥è¿™äº›æ–‡ä»¶ç±»å‹")

    return suggestions

def detect_large_files_in_history(limit_mb=5):
    """æ£€æµ‹Gitä»“åº“å†å²ä¸­çš„å¤§æ–‡ä»¶"""
    cmd = "git rev-list --objects --all | git cat-file --batch-check='%(objecttype) %(objectname) %(objectsize) %(rest)' | awk '$1 == \"blob\" && $3 >= 5242880' | sort -k3nr | head -n 20"

    try:
        result = subprocess.run(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            shell=True,
            encoding='utf-8',
            errors='ignore'
        )
        output = result.stdout.strip() if result.stdout else ""

        if not output:
            return []

        large_files = []
        for line in output.split('\n'):
            if not line.strip():
                continue

            parts = line.split()
            if len(parts) >= 4:
                object_type, object_name, size_str, *file_path = parts
                if object_type == "blob":
                    try:
                        size_bytes = int(size_str)
                        file_path_str = ' '.join(file_path)
                        large_files.append((file_path_str, size_bytes))
                    except ValueError:
                        continue

        return large_files
    except Exception as e:
        print(f"æ£€æµ‹å†å²å¤§æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return []

def main():
    """ä¸»å‡½æ•°"""
    print("\n======= å¢å¼ºç‰ˆ Gitæäº¤ä¿¡æ¯ç”Ÿæˆå™¨ v2.0 =======\n")
    print("è¯¥å·¥å…·ä¼šåˆ†ææ‚¨çš„ä»£ç å˜æ›´ï¼Œç”Ÿæˆåæ˜ ä¸šåŠ¡ä»·å€¼çš„æäº¤ä¿¡æ¯")
    print("ä½œè€…ï¼šAIåŠ©æ‰‹ (åŸºäºåŸå§‹å·¥å…·ä¼˜åŒ–)")

    # æ¸…ç†æ—§æ–‡ä»¶
    print("\næ­£åœ¨æ¸…ç†æ—§æ–‡ä»¶...")
    cleanup_old_files()

    # è·å–å·²æš‚å­˜çš„å˜æ›´
    print("\næ­£åœ¨è·å–Gitæš‚å­˜åŒºå˜æ›´...")
    changes = get_staged_files()

    if not changes:
        print("æ²¡æœ‰æ£€æµ‹åˆ°æš‚å­˜åŒºæœ‰ä»»ä½•æ–‡ä»¶å˜æ›´ã€‚è¯·å…ˆä½¿ç”¨ git add æ·»åŠ è¦æäº¤çš„æ–‡ä»¶ã€‚")
        return

    print(f"âœ“ æˆåŠŸæ£€æµ‹åˆ° {len(changes)} ä¸ªæ–‡ä»¶å˜æ›´")

    # æ£€æŸ¥Gité…ç½®
    git_config = check_git_config()
    lfs_status = "å·²å®‰è£…" if git_config["lfs_enabled"] else "æœªå®‰è£…"
    print(f"Git LFSçŠ¶æ€ï¼š{lfs_status}")

    if git_config["is_github"]:
        print("ç›®æ ‡ä»“åº“ï¼šGitHub (å¯¹æ–‡ä»¶å¤§å°æœ‰ä¸¥æ ¼é™åˆ¶)")
    elif git_config["is_gitlab"]:
        print("ç›®æ ‡ä»“åº“ï¼šGitLab")

    # ä¿å­˜å˜æ›´åˆ°æ–‡ä»¶
    changes_file = save_changes_to_file(changes)
    print(f"âœ“ å·²å°†å˜æ›´æ–‡ä»¶åˆ—è¡¨ä¿å­˜è‡³: {changes_file}")    # æ£€æŸ¥å½“å‰å˜æ›´ä¸­çš„å¤§æ–‡ä»¶
    large_files, warning_files, lfs_suggestion_files = check_large_files(changes)
    has_large_files = bool(large_files)

    if large_files:
        print("\nâš ï¸ ä¸¥é‡è­¦å‘Š: æ£€æµ‹åˆ°ä»¥ä¸‹æ–‡ä»¶è¶…è¿‡GitHub/GitLabå¤§å°é™åˆ¶(100MB)ï¼")
        print("è¿™äº›æ–‡ä»¶å°†å¯¼è‡´ 'pre-receive hook declined' é”™è¯¯ï¼Œé˜»æ­¢æ‚¨çš„æ¨é€ï¼š")
        for filepath, size in large_files:
            print(f"  - {filepath}: {format_file_size(size)}")

        # æä¾›è§£å†³æ–¹æ¡ˆ
        print("\nğŸ› ï¸ è§£å†³æ–¹æ¡ˆï¼š")
        for suggestion in suggest_fix_for_large_files(large_files, git_config):
            print(f"{suggestion}")

        # æ£€æŸ¥å†å²ä¸­çš„å¤§æ–‡ä»¶
        print("\næ­£åœ¨æ£€æŸ¥ä»“åº“å†å²ä¸­çš„å¤§æ–‡ä»¶...")
        historical_large_files = detect_large_files_in_history()
        if historical_large_files:
            print("\nğŸ“‹ åœ¨Gitå†å²ä¸­æ£€æµ‹åˆ°ä»¥ä¸‹å¤§æ–‡ä»¶ï¼Œè¿™äº›ä¹Ÿå¯èƒ½å¯¼è‡´æ¨é€é—®é¢˜ï¼š")
            for filepath, size in historical_large_files[:5]:  # åªæ˜¾ç¤ºæœ€å¤§çš„5ä¸ª
                print(f"  - {filepath}: {format_file_size(size)}")
            if len(historical_large_files) > 5:
                print(f"  ... ä»¥åŠå…¶ä»– {len(historical_large_files) - 5} ä¸ªå¤§æ–‡ä»¶")

            print("\nğŸ’¡ æ¸…ç†å†å²å¤§æ–‡ä»¶çš„è§£å†³æ–¹æ¡ˆï¼š")
            print("  1. ä½¿ç”¨ BFG Repo-Cleaner æˆ– git filter-branch æ¸…ç†å†å²")
            print("  2. æ‰§è¡Œ cleanup_large_files.bat è„šæœ¬è¿›è¡Œè‡ªåŠ¨æ¸…ç†")
            print("  3. æ›´æ–° .gitignore é˜²æ­¢å†æ¬¡æ·»åŠ å¤§æ–‡ä»¶")

        proceed = input("\nè¿™äº›å¤§æ–‡ä»¶ä¼šå¯¼è‡´æ¨é€å¤±è´¥ã€‚æ˜¯å¦ä»è¦ç»§ç»­ç”Ÿæˆæäº¤ä¿¡æ¯? (y/n): ")
        if proceed.lower() != 'y':
            print("å·²å–æ¶ˆã€‚è¯·å…ˆå¤„ç†å¤§æ–‡ä»¶é—®é¢˜ã€‚")
            return

    if warning_files:
        print("\nâš ï¸ è­¦å‘Š: æ£€æµ‹åˆ°ä»¥ä¸‹æ–‡ä»¶æ¥è¿‘å¤§å°é™åˆ¶(50MB+)ï¼š")
        for filepath, size in warning_files:
            print(f"  - {filepath}: {format_file_size(size)}")
        print("è™½ç„¶å¯ä»¥æäº¤ï¼Œä½†è¿™äº›å¤§æ–‡ä»¶ä¼šå½±å“Gitä»“åº“æ€§èƒ½ï¼Œå»ºè®®ä½¿ç”¨Git LFSç®¡ç†ã€‚")

    if lfs_suggestion_files and not (large_files or warning_files):
        print("\nğŸ’¡ æç¤º: æ£€æµ‹åˆ°ä»¥ä¸‹è¾ƒå¤§æ–‡ä»¶(5MB+)ï¼Œå»ºè®®ä½¿ç”¨Git LFSç®¡ç†ï¼š")
        for filepath, size in lfs_suggestion_files[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
            print(f"  - {filepath}: {format_file_size(size)}")
        if len(lfs_suggestion_files) > 3:
            print(f"  ... ä»¥åŠå…¶ä»– {len(lfs_suggestion_files) - 3} ä¸ªæ–‡ä»¶")

    # ç”Ÿæˆæäº¤ä¿¡æ¯
    print("\nğŸ” æ­£åœ¨æ·±å…¥åˆ†æä»£ç å˜æ›´...")
    print("    - åˆ†ææäº¤ç±»å‹...")
    print("    - æå–åŠŸèƒ½ç‰¹æ€§...")
    print("    - è¯„ä¼°å˜æ›´ä»·å€¼...")
    print("    - ç”Ÿæˆä¼˜åŒ–çš„æäº¤ä¿¡æ¯...")

    commit_msg = generate_commit_message(changes)

    # å¦‚æœæœ‰å¤§æ–‡ä»¶é—®é¢˜ï¼Œåœ¨æäº¤ä¿¡æ¯ä¸­æé†’
    if has_large_files:
        commit_msg += "\n\nâš ï¸ æ³¨æ„ï¼šæ­¤æäº¤åŒ…å«è¶…å¤§æ–‡ä»¶ï¼Œè¯·ç¡®ä¿å·²é…ç½®Git LFSæˆ–æ›´æ–°äº†.gitignoreã€‚"    # è¾“å‡ºç»“æœ
    print("\nâœ¨ ==== ä»·å€¼é©±åŠ¨çš„æäº¤ä¿¡æ¯ ==== âœ¨\n")
    # æ ¼å¼åŒ–è¾“å‡ºï¼Œç¡®ä¿ç»ˆç«¯å¯ä»¥æ­£å¸¸æ˜¾ç¤º
    for line in commit_msg.split('\n'):
        if len(line) > 100:  # å¦‚æœè¡Œå¤ªé•¿ï¼Œå¯èƒ½ä¼šåœ¨ç»ˆç«¯ä¸Šæ˜¾ç¤ºä¸å…¨
            print(f"{line[:97]}...")
        else:
            print(line)
    print("\n================================\n")    # ä¿å­˜æäº¤ä¿¡æ¯åˆ°æ–‡ä»¶
    commit_msg_file = "commit_message.txt"
    with open(commit_msg_file, 'w', encoding='utf-8') as f:
        f.write(commit_msg)

    print(f"âœ“ æäº¤ä¿¡æ¯å·²ä¿å­˜åˆ°æ–‡ä»¶: {commit_msg_file}")
    print("\nğŸ’» ä½¿ç”¨æ–¹æ³•:")
    print(f'  1. ç›´æ¥ä½¿ç”¨ï¼šgit commit -F "{commit_msg_file}"')
    print(f'  2. ç¼–è¾‘åä½¿ç”¨ï¼šç”¨ç¼–è¾‘å™¨æ‰“å¼€ {commit_msg_file}ï¼Œä¿®æ”¹åå†ä½¿ç”¨')

    # äº¤äº’å¼æäº¤åŠŸèƒ½
    print("\nğŸš€ è‡ªåŠ¨æ‰§è¡ŒåŠŸèƒ½:")
    try:
        commit_choice = input("æ˜¯å¦ç«‹å³æ‰§è¡Œ git commitï¼Ÿ(y/n): ").strip().lower()
        if commit_choice in ['y', 'yes']:
            print(f"æ­£åœ¨æ‰§è¡Œï¼šgit commit -F \"{commit_msg_file}\"")
            import subprocess
            # ä½¿ç”¨UTF-8ç¼–ç é¿å…GBKç¼–ç é”™è¯¯
            result = subprocess.run(['git', 'commit', '-F', commit_msg_file],
                                  capture_output=True, text=True, cwd='.',
                                  encoding='utf-8', errors='ignore')
            if result.returncode == 0:
                print("âœ… Git commit æ‰§è¡ŒæˆåŠŸï¼")
                if result.stdout:
                    print(result.stdout.strip())

                # è¯¢é—®æ˜¯å¦æ‰§è¡Œ git push
                push_choice = input("\næ˜¯å¦ç«‹å³æ‰§è¡Œ git pushï¼Ÿ(y/n): ").strip().lower()
                if push_choice in ['y', 'yes']:
                    print("æ­£åœ¨æ‰§è¡Œï¼šgit push")
                    push_result = subprocess.run(['git', 'push'],
                                               capture_output=True, text=True, cwd='.',
                                               encoding='utf-8', errors='ignore')
                    if push_result.returncode == 0:
                        print("âœ… Git push æ‰§è¡ŒæˆåŠŸï¼")
                        if push_result.stdout:
                            print(push_result.stdout.strip())
                    else:
                        print("âŒ Git push æ‰§è¡Œå¤±è´¥ï¼š")
                        if push_result.stderr:
                            print(push_result.stderr.strip())
                else:
                    print("â­ï¸ è·³è¿‡ git pushï¼Œæ‚¨å¯ä»¥ç¨åæ‰‹åŠ¨æ‰§è¡Œ")
            else:
                print("âŒ Git commit æ‰§è¡Œå¤±è´¥ï¼š")
                if result.stderr:
                    print(result.stderr.strip())
        else:
            print("â­ï¸ è·³è¿‡ git commitï¼Œæ‚¨å¯ä»¥ç¨åæ‰‹åŠ¨æ‰§è¡Œ")
    except KeyboardInterrupt:
        print("\nâ¹ï¸ æ“ä½œå·²å–æ¶ˆ")
    except Exception as e:
        print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{str(e)}")

    # æ·»åŠ æ–°åŠŸèƒ½è¯´æ˜
    print("\nğŸŒŸ æäº¤ä¿¡æ¯äº®ç‚¹:")
    print("  - çªå‡ºä»£ç å˜æ›´çš„ä¸šåŠ¡ä»·å€¼")
    print("  - è‡ªåŠ¨æ£€æµ‹æ¨¡å—å’ŒåŠŸèƒ½å…³ç³»")
    print("  - æ™ºèƒ½åˆ†ç±»ä¸åŒç±»å‹çš„ä»£ç å˜æ›´")
    print("  - ä¼˜åŒ–æ ¼å¼ï¼Œç¬¦åˆå›¢é˜Ÿæœ€ä½³å®è·µ")

    if has_large_files:
        print("\nâš ï¸ å†æ¬¡æé†’ï¼šå¦‚æœä¸å¤„ç†å¤§æ–‡ä»¶é—®é¢˜ï¼Œæ‚¨çš„æ¨é€å°†è¢«æ‹’ç»('pre-receive hook declined')")
        print("å¤„ç†æ–¹æ³•è¯·å‚è€ƒä¸Šé¢çš„è§£å†³æ–¹æ¡ˆã€‚")


if __name__ == "__main__":
    main()
