"""
OCRå¼‚æ­¥ä»»åŠ¡å¤„ç†
åŸºäºCeleryå®ç°çš„å¼‚æ­¥OCRä»»åŠ¡
"""

import os
import logging
from pathlib import Path
from django.utils import timezone
from django.conf import settings
from celery import shared_task
import traceback
import datetime
import time
import json
import base64
import io
from PIL import Image
from django.template.loader import render_to_string
from django.db.models import Q

from .models import OCRTask, OCRResult, OCRCache, OCRCacheHit
from apps.ocr.services.ocr_service import OCRService
from apps.ocr.services.two_stage_ocr import TwoStageOCRService
from .services.gitlab import (
    DownloadResult,
    GitLabService,
    GitLabConfig,
)
from .services.path_utils import PathUtils
from apps.notifications.tasks import notify_ocr_task_progress
from .services.compare_service import TransRepoConfig
from .serializers import OCRTaskSerializer, OCRResultSerializer
from enum import Enum

class BaseEnum(Enum):
    def __new__(cls, value, label, order, type=None, color=None):
        obj = object.__new__(cls)
        obj._value_ = value
        obj.label = label
        obj.order = order
        obj.type = type
        obj.color = color
        return obj

class ocrResultTypeEnum(BaseEnum):
    ALL = ("", "å…¨éƒ¨", 0, None, "#FFF")
    RIGHT = (1, "æ­£ç¡®", 2, "success", "#90e9a6ff")
    WRONG = (2, "é”™è¯¯", 3, "danger", "#faa7a7ff")

class ocrIsVerifiedEnum(BaseEnum):
    ALL = (None, "å…¨éƒ¨", 1)
    VERIFIED = (True, "å·²å®¡æ ¸", 2)
    UNVERIFIED = (False, "å¾…å®¡æ ¸", 3)

class ocrIsTranslatedEnum(BaseEnum):
    ALL = (None, "å…¨éƒ¨", 1)
    TRANSLATED = (True, "å·²ç¿»è¯‘", 2)
    UNTRANSLATED = (False, "æœªç¿»è¯‘", 3)

class ocrIsMatchEnum(BaseEnum):
    ALL = (None, "å…¨éƒ¨", 1, "")
    MATCH = (True, "å·²åŒ¹é…", 2)
    UNMATCH = (False, "æœªåŒ¹é…", 3)

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# å®šä¹‰å¸¸é‡ - ä½¿ç”¨PathUtilsä»config.iniè·å–è·¯å¾„
REPOS_DIR = PathUtils.get_ocr_repos_dir()
UPLOADS_DIR = PathUtils.get_ocr_uploads_dir()
RESULTS_DIR = PathUtils.get_ocr_results_dir()


# é€šç”¨å·¥å…·å‡½æ•°ï¼šè¯­è¨€å‘½ä¸­ä¸æ–‡æœ¬è¿‡æ»¤ï¼ˆé¿å…ä»»ä½•ç¡¬ç¼–ç è¯­è¨€ç ï¼‰
def _is_language_hit(texts, target_languages):
    """åˆ¤æ–­è¯†åˆ«ç»“æœæ˜¯å¦å‘½ä¸­ä»»ä¸€ç›®æ ‡è¯­è¨€ã€‚

    Args:
        texts (list[str]): æ–‡æœ¬è¯†åˆ«å¾—åˆ°çš„æ–‡æœ¬åˆ—è¡¨ï¼Œå…è®¸ä¸ºç©ºåˆ—è¡¨æˆ–Noneã€‚
        target_languages (list[str] | None): ç›®æ ‡è¯­è¨€ä»£ç åˆ—è¡¨ï¼Œä¾‹å¦‚ ['ch','en']ã€‚
            è‹¥ä¸ºNoneæˆ–ç©ºåˆ—è¡¨ï¼Œåˆ™é»˜è®¤ä½¿ç”¨ ['ch']ã€‚

    Returns:
        bool: å½“ä¸”ä»…å½“ `texts` ä¸­åŒ…å«ä»»ä¸€ `target_languages` å¯¹åº”è¯­è¨€çš„æ–‡æœ¬æ—¶
        è¿”å› Trueï¼Œå¦åˆ™è¿”å› Falseã€‚

    Raises:
        æ— æ˜¾å¼æŠ›å‡ºã€‚å†…éƒ¨å¼‚å¸¸ä¼šè¢«åå¹¶ä»¥ä¿è¯ç¨³å¥æ€§ã€‚

    Example:
        >>> _is_language_hit(['ä½ å¥½','hello'], ['en'])
        True
        >>> _is_language_hit(['ä½ å¥½'], ['en'])
        False

    Notes:
        - ä¸ºä¿è¯å¥å£®æ€§ï¼Œå•é¡¹è¯­è¨€åŒ¹é…å¼‚å¸¸ä¸ä¼šå½±å“æ•´ä½“åˆ¤æ–­ï¼Œä¼šè¢«å¿½ç•¥ç»§ç»­ã€‚
        - è¯¥å‡½æ•°ä¸åšè¯­è¨€ç åˆæ³•æ€§æ ¡éªŒï¼Œé»˜è®¤äº¤ç”± `OCRService.check_language_match` å¤„ç†ã€‚
    """
    safe_langs = target_languages or ['ch']
    for lang in safe_langs:
        try:
            if OCRService.check_language_match(texts or [], lang):
                return True
        except Exception:
            # å•é¡¹è¯­è¨€åŒ¹é…å¼‚å¸¸ä¸å½±å“æ•´ä½“åˆ¤æ–­
            continue
    return False


def _filter_texts_by_languages(texts, target_languages):
    """æŒ‰ç›®æ ‡è¯­è¨€è¿‡æ»¤æ–‡æœ¬å¹¶è¿”å›å‘½ä¸­é¡¹ã€‚

    Args:
        texts (list[str]): æ–‡æœ¬è¯†åˆ«å¾—åˆ°çš„æ–‡æœ¬åˆ—è¡¨ï¼Œå…è®¸ä¸ºç©ºåˆ—è¡¨æˆ–Noneã€‚
        target_languages (list[str] | None): ç›®æ ‡è¯­è¨€ä»£ç åˆ—è¡¨ï¼Œä¾‹å¦‚ ['ch','en']ã€‚
            è‹¥ä¸ºNoneæˆ–ç©ºåˆ—è¡¨ï¼Œåˆ™é»˜è®¤ä½¿ç”¨ ['ch']ã€‚

    Returns:
        list[str]: æ‰€æœ‰è¢«ä»»ä¸€ç›®æ ‡è¯­è¨€è§„åˆ™å‘½ä¸­çš„æ–‡æœ¬é¡¹ï¼ŒæŒ‰åŸé¡ºåºè¿”å›ã€‚

    Raises:
        æ— æ˜¾å¼æŠ›å‡ºã€‚å†…éƒ¨å¼‚å¸¸ä¼šè¢«åå¹¶ä»¥ä¿è¯ç¨³å¥æ€§ã€‚

    Example:
        >>> _filter_texts_by_languages(['ä½ å¥½','hello'], ['en'])
        ['hello']

    Notes:
        - ä½¿ç”¨ `OCRService.check_language_match` å¯¹å•æ¡æ–‡æœ¬è¿›è¡Œåˆ¤å®šã€‚
        - å•æ¡åˆ¤å®šå¼‚å¸¸ä¸ä¼šä¸­æ–­æµç¨‹ï¼Œä»…è·³è¿‡è¯¥æ¡ã€‚
    """
    safe_langs = target_languages or ['ch']
    filtered = []
    for text in texts or []:
        try:
            if any(OCRService.check_language_match([text], lang) for lang in safe_langs):
                filtered.append(text)
        except Exception:
            continue
    return filtered


@shared_task()
def process_ocr_task(task_id):
    """è°ƒåº¦å¹¶å¤„ç†æŒ‡å®š OCR ä»»åŠ¡ã€‚

    Args:
        task_id (int|str): `OCRTask` ä¸»é”®IDã€‚

    Returns:
        dict: æ‰§è¡Œç»“æœå­—å…¸ï¼ŒåŒ…å« `status` ä¸å¯é€‰çš„ `task_id`/`message` ç­‰ã€‚

    Raises:
        å¼‚å¸¸ä¼šè¢«æ•è·è®°å½•åˆ°æ—¥å¿—ï¼Œå¹¶å›å†™ä»»åŠ¡çŠ¶æ€ä¸º failedï¼Œä¸å‘å¤–æŠ›å‡ºã€‚

    Example:
        ç”± Celery Worker å¼‚æ­¥è°ƒç”¨ï¼š
        >>> process_ocr_task.delay(123)

    Notes:
        - æ‰¹é‡å†™åº“é€»è¾‘åœ¨ `MultiThreadOCR` å†…éƒ¨å®Œæˆã€‚
        - ç›®æ ‡è¯­è¨€ä» `task.config['target_languages']` åŠ¨æ€è·å–ï¼Œæœªè®¾ç½®é»˜è®¤ ['ch']ã€‚
        - å‘½ä¸­è§„åˆ™ç»Ÿä¸€åœ¨ `_is_language_hit` / `_filter_texts_by_languages` ä¸­å¤„ç†ã€‚
    """
    logger.info(f"å¼€å§‹å¤„ç†OCRä»»åŠ¡: {task_id}")

    try:
        # step1. è·å–ä»»åŠ¡ä¿¡æ¯
        logger.info(f"å¼€å§‹æŸ¥è¯¢OCRä»»åŠ¡: {task_id}, ç±»å‹: {type(task_id)}")
        
        # æ·»åŠ é‡è¯•æœºåˆ¶ï¼Œå¤„ç†æ•°æ®åº“äº‹åŠ¡å»¶è¿Ÿé—®é¢˜
        task = None
        max_retries = 5
        retry_delay = 0.3  # 300æ¯«ç§’
        
        for attempt in range(max_retries):
            logger.info(f"ç¬¬{attempt + 1}æ¬¡å°è¯•æŸ¥è¯¢ä»»åŠ¡: {task_id}")
            task = OCRTask.objects.all_teams().filter(id=task_id).first()
            if task:
                logger.info(f"âœ… ç¬¬{attempt + 1}æ¬¡å°è¯•æˆåŠŸæ‰¾åˆ°OCRä»»åŠ¡: {task.id}")
                break
            
            # æŸ¥è¯¢å¤±è´¥ï¼Œè®°å½•è°ƒè¯•ä¿¡æ¯
            logger.warning(f"âŒ ç¬¬{attempt + 1}æ¬¡å°è¯•æœªæ‰¾åˆ°ä»»åŠ¡ {task_id}")
            
            if attempt < max_retries - 1:
                logger.warning(f"â³ {retry_delay}ç§’åé‡è¯•...")
                time.sleep(retry_delay)
                retry_delay *= 1.5  # æŒ‡æ•°é€€é¿
            else:
                # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œè®°å½•è¯¦ç»†è°ƒè¯•ä¿¡æ¯
                all_tasks = OCRTask.objects.all_teams().values_list('id', 'name', 'status', 'created_at')
                recent_tasks = list(all_tasks.order_by('-created_at')[:10])
                logger.error(f"OCRä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
                logger.error(f"æ•°æ®åº“ä¸­æœ€è¿‘10ä¸ªä»»åŠ¡: {recent_tasks}")
                logger.error(f"æŸ¥è¯¢æ¡ä»¶: id={task_id}")
                return {"status": "error", "message": f"OCRä»»åŠ¡ä¸å­˜åœ¨: {task_id}"}
        
        logger.info(f"æˆåŠŸæ‰¾åˆ°OCRä»»åŠ¡: {task.id}, åç§°: {task.name}, çŠ¶æ€: {task.status}")

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        notify_ocr_task_progress({
            "id": task_id,
            "status": 'running',
            "start_time": timezone.now(),
        })

        # è·å–ç›®æ ‡è¯­è¨€
        task_config = task.config or {}
        target_languages = task_config.get('target_languages', ['ch'])  # é»˜è®¤æ£€æµ‹ä¸­æ–‡ï¼ˆå®˜æ–¹è¯­è¨€ç ï¼‰
        logger.info(f"ä»»åŠ¡é…ç½®: {task_config}")
        logger.info(f"ç›®æ ‡è¯­è¨€: {target_languages}")

        rec_score_raw = task_config.get('rec_score_thresh') # cong
        if rec_score_raw is None:
            rec_score_raw = task_config.get('rec score thresh', 0.5)
        try:
            rec_score_thresh = float(rec_score_raw)
        except (TypeError, ValueError):
            logger.error("ä»»åŠ¡é…ç½®è¯†åˆ«é˜ˆå€¼æ— æ•ˆ: %s", rec_score_raw)
            raise ValueError("ä»»åŠ¡é…ç½®è¯†åˆ«é˜ˆå€¼æ— æ•ˆ")
        if rec_score_thresh < 0 or rec_score_thresh > 1:
            logger.error("ä»»åŠ¡è¯†åˆ«é˜ˆå€¼è¶…å‡ºèŒƒå›´: %.4f", rec_score_thresh)
            raise ValueError("ä»»åŠ¡è¯†åˆ«é˜ˆå€¼è¶…å‡ºèŒƒå›´")
        logger.info("ä»»åŠ¡ä½¿ç”¨è¯†åˆ«é˜ˆå€¼: %.2f", rec_score_thresh)


        # ä»å‘½ä»¤è¡ŒæŒ‡å®šçš„é…ç½®æ–‡ä»¶è¯»å–OCRå¤šçº¿ç¨‹é…ç½®
        config = settings.CFG._config
        ocr_max_workers = config.getint('ocr', 'ocr_max_workers', fallback=4)

        logger.warning(f"ä»é…ç½®æ–‡ä»¶è¯»å–OCRé…ç½®: max_workers={ocr_max_workers}, é…ç½®æ–‡ä»¶: {settings.CFG._config_path}")

        # ä¸ºäº†æ–¹ä¾¿è°ƒè¯•ï¼Œç›´æ¥ä½¿ç”¨å›ºå®šç›®å½•ï¼Œä¸ç®¡ä»»åŠ¡ç±»å‹
        debug_dir = PathUtils.get_debug_dir()
        debug_status = False

        # æ‰“å°å®Œæ•´çš„è°ƒè¯•ç›®å½•è·¯å¾„ï¼Œæ–¹ä¾¿æ’æŸ¥é—®é¢˜
        logger.info(f"è°ƒè¯•ç›®å½•å®Œæ•´è·¯å¾„: {os.path.abspath(debug_dir)}")

        # step2. è·å–å¾…æ£€æµ‹ç›®å½•è·¯å¾„
        # è·å–å¾…æ£€æµ‹ç›®å½•è·¯å¾„ & å¾…æ£€æµ‹æ–‡ä»¶ç›¸å¯¹è·¯å¾„
        target_dir = task_config.get("target_dir")
        target_path = task_config.get("target_path")
        check_dir = ""
        
        logger.info(f"ä»»åŠ¡é…ç½® - target_dir: {target_dir}")
        logger.info(f"ä»»åŠ¡é…ç½® - target_path: {target_path}")
        logger.info(f"ä»»åŠ¡é…ç½® - source_type: {task.source_type}")

        # æ£€æŸ¥è°ƒè¯•ç›®å½•æ˜¯å¦å­˜åœ¨ ä¸” å¼€å¯è°ƒè¯•ï¼ˆå¿«é€Ÿä½¿ç”¨æŒ‡å®šç›®å½•å›¾ç‰‡æ’æŸ¥è¯†åˆ«é€»è¾‘æ—¶ä½¿ç”¨ï¼‰
        if os.path.exists(debug_dir) and debug_status:
            logger.info(f"ä½¿ç”¨è°ƒè¯•ç›®å½•: {debug_dir}")
            check_dir = debug_dir
        else:
            # å¦‚æœè°ƒè¯•ç›®å½•ä¸å­˜åœ¨ï¼Œåˆ™ä½¿ç”¨æ­£å¸¸æµç¨‹
            logger.warning(f"è°ƒè¯•ç›®å½•:[ {debug_dir} ] ä¸å­˜åœ¨æˆ–æœªå¼€å¯è°ƒè¯•æ¨¡å¼ï¼Œä½¿ç”¨æ­£å¸¸æµç¨‹")

            # æ ¹æ®ä»»åŠ¡ç±»å‹ç¡®å®šæ£€æŸ¥ç›®å½•
            if task.source_type == 'upload':
                # å¯¹äºä¸Šä¼ ä»»åŠ¡ï¼Œtarget_diræ˜¯ç›¸å¯¹è·¯å¾„ï¼Œéœ€è¦ä¸MEDIA_ROOTæ‹¼æ¥
                check_dir = os.path.join(settings.MEDIA_ROOT, target_dir)
            elif task.source_type == 'git':
                # Gitä»»åŠ¡ï¼šåŠ¨æ€è·å–reposåŸºç¡€ç›®å½•ï¼Œé¿å…ä½¿ç”¨æ—§é…ç½®ä¸­çš„è·¯å¾„
                repos_base_dir = PathUtils.get_ocr_repos_dir()
                check_dir = os.path.join(repos_base_dir, target_path)
                logger.info(f"Gitä»»åŠ¡æ£€æŸ¥ç›®å½•: {check_dir} (åŸºç¡€ç›®å½•: {repos_base_dir}, ä»“åº“å: {target_path})")
                git_service = GitLabService(
                    GitLabConfig(
                        repo_url=task.git_repository.url,
                        access_token=task.git_repository.token,
                    )
                )
                notify_ocr_task_progress({
                    "id": task_id,
                    "remark": "æ­£åœ¨åŒæ­¥ Git ä»“åº“...",
                })
                result: DownloadResult = git_service.download_files_with_git_clone(
                    repo_base_dir=check_dir,
                    branch=task_config.get("branch", "develop"),
                )
                if not result.success:
                    logger.error(f"Gitä»“åº“ä¸‹è½½å¤±è´¥: {result.message}")
                    notify_ocr_task_progress({
                        "id": task_id,
                        "status": 'failed',
                        "end_time": timezone.now(),
                        "remark": f"Gitä»“åº“ä¸‹è½½å¤±è´¥: {result.message}",
                    })
                    return {"status": "error", "message": f"Gitä»“åº“ä¸‹è½½å¤±è´¥: {result.message}"}
            else:
                logger.error(f"ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {task.source_type}")
                notify_ocr_task_progress({
                    "id": task_id,
                    "status": 'failed',
                    "end_time": timezone.now(),
                    "remark": f"ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {task.source_type}",
                })
                return {"status": "error", "message": f"ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {task.source_type}"}

        # æ£€æŸ¥ç›®æ ‡ç›®å½•
        if not check_dir or not os.path.exists(check_dir):
            logger.error(f"OCRå¾…æ£€æµ‹ç›®å½•ä¸å­˜åœ¨: {check_dir}")
            notify_ocr_task_progress({
                "id": task_id,
                "status": 'failed',
                "end_time": timezone.now(),
                "remark": f"OCRå¾…æ£€æµ‹ç›®å½•ä¸å­˜åœ¨: {check_dir}",
            })
            return {"status": "error", "message": f"OCRå¾…æ£€æµ‹ç›®å½•ä¸å­˜åœ¨: {check_dir}"}

        # step4. æ‰§è¡Œä¸»é€»è¾‘
        # åˆå§‹åŒ–å¤šçº¿ç¨‹OCRæœåŠ¡
        logger.warning(f"åˆå§‹åŒ–å¤šçº¿ç¨‹OCRæœåŠ¡ ( æœ€å¤§å·¥ä½œçº¿ç¨‹: {ocr_max_workers})")
        # multi_thread_ocr = MultiThreadOCR(
        #     task,
        #     lang="ch",  # é»˜è®¤ä½¿ç”¨ä¸­æ–‡æ¨¡å‹
        #     max_workers=ocr_max_workers,  # ä½¿ç”¨é…ç½®çš„å·¥ä½œçº¿ç¨‹æ•°
        #     match_languages=target_languages  # å°†å‘½ä¸­åˆ¤å®šè¯­è¨€åŠ¨æ€ä¼ å…¥ï¼Œé¿å…ç¡¬ç¼–ç 
        # )

        # ================== OCRè¯†åˆ«å‰å…ˆåˆ©ç”¨ Cache è¿‡æ»¤ï¼Œé¿å…é‡å¤è¯†åˆ«  =========================
        enable_cache = task_config.get('enable_cache', True)
        img_exts_init = {'.jpg', '.jpeg', '.png', '.bmp', '.webp', '.tif', '.tiff'}
        total_images = 0
        hit_hashes = set()
        image_paths = []
        msg = ""
        
        if not enable_cache:
            for root_dir, _, files in os.walk(check_dir):
                for file_name in files:
                    file_ext = os.path.splitext(file_name)[1].lower()
                    if file_ext not in img_exts_init:
                        continue
                    total_images += 1
            msg = f"æœªå¯ç”¨ç¼“å­˜, å¾…å¤„ç†å›¾ç‰‡: {total_images}"
            logger.warning(msg)
        else:
            # åˆå§‹åŒ–è¿›åº¦(ä»¥å¾…å¤„ç†å›¾ç‰‡æ€»æ•°ä¸ºå‡†)
            abspath_to_hash = dict()
            try:
                notify_ocr_task_progress({
                "id": task_id,
                "remark": "æ­£åœ¨ä½¿ç”¨OCRç¼“å­˜è¿›è¡Œé¢„è¿‡æ»¤...",
                })

                for root_dir, _, files in os.walk(check_dir):
                    for file_name in files:
                        file_ext = os.path.splitext(file_name)[1].lower()
                        if file_ext not in img_exts_init:
                            continue
                        img_abspath = os.path.join(root_dir, file_name)
                        img_hash = OCRService.calculate_image_hash(img_abspath)
                        abspath_to_hash[img_abspath] = img_hash
                        total_images += 1

                # å°è¯•å‘½ä¸­ç¼“å­˜
                all_hashes_list = list(abspath_to_hash.values())
                hit_hashes = OCRCacheHit.try_hit(all_hashes_list, task_id=task_id)
                image_paths = [img_path for img_path, h in abspath_to_hash.items() if h not in hit_hashes]

                if len(image_paths) == 0:
                    logger.warning("âš¡æ‰€æœ‰å›¾ç‰‡å‡å‘½ä¸­OCRç¼“å­˜, æ— éœ€é‡å¤è¯†åˆ«")
                    task.calculate_match_rate_by_related_results()
                    notify_ocr_task_progress({
                        "id": task_id,
                        "status": 'completed',
                        "end_time": timezone.now(),
                        "total_images": total_images,
                        "verified_images": task.total_verified,
                        "processed_images": total_images,
                        "remark": f"âœ… ä»»åŠ¡æ‰§è¡Œå®Œæ¯•",
                    })
                    return {"status": "success", "task_id": task_id}

                msg = f"âš¡ç¼“å­˜è¿‡æ»¤å®Œæˆ: T{total_images};H{len(hit_hashes)};P{len(image_paths)}"
                logger.info(msg)
            except Exception as _init_prog_err:
                logger.warning(f"ä½¿ç”¨OCRç¼“å­˜è¿›è¡Œé¢„è¿‡æ»¤å‡ºé”™: {_init_prog_err}")
                image_paths = []
        notify_ocr_task_progress({
            "id": task_id,
            "total_images": total_images,
            "remark": msg,
        })
        # ==========================================================================

        # ä½¿ç”¨ä¸¤é˜¶æ®µOCRæ£€æµ‹æœåŠ¡ï¼Œé›†æˆäº†è°ƒä¼˜åçš„å‚æ•°é…ç½®
        # ä»ä»»åŠ¡é…ç½®ä¸­è·å–æ€§èƒ½é…ç½®åç§°
        performance_config_name = task_config.get('performance_config', 'balanced')
        logger.warning(f"åˆå§‹åŒ–ä¸¤é˜¶æ®µOCRæœåŠ¡ï¼Œæ€§èƒ½é…ç½®: {performance_config_name}")

        # ä»ä»»åŠ¡é…ç½®è¯»å–å¼€å…³ï¼ˆæœªè®¾ç½®é»˜è®¤Falseï¼‰
        try:
            enable_draw = bool(task_config.get('rounds_draw_enable', False))
        except Exception:
            enable_draw = False
        try:
            enable_copy = bool(task_config.get('rounds_copy_enable', False))
        except Exception:
            enable_copy = False
        try:
            enable_annotate = bool(task_config.get('rounds_annotate_enable', False))
        except Exception:
            enable_annotate = False

        start_time = time.time()
        
        # åˆå§‹åŒ–ä¸¤é˜¶æ®µOCRæœåŠ¡ï¼ˆé»˜è®¤ä¸å¯ç”¨è¯¦ç»†æŠ¥å‘Šï¼‰
        two_stage_service = TwoStageOCRService(
            performance_config_name,
            enable_detailed_report=False,
            rec_score_thresh=rec_score_thresh
        )
        
        # å‡†å¤‡è¾“å…¥å›¾ç‰‡åˆ—è¡¨
        if image_paths:
            # ä½¿ç”¨ç¼“å­˜è¿‡æ»¤åçš„å›¾ç‰‡åˆ—è¡¨ï¼ŒåŒæ—¶è¿‡æ»¤å›¾ç‰‡æ ¼å¼
            img_exts = {'.jpg', '.jpeg', '.png'}
            input_images = [
                img_path for img_path in image_paths
                if os.path.splitext(img_path)[1].lower() in img_exts
            ]
            if len(input_images) < len(image_paths):
                logger.info(f"æ ¼å¼è¿‡æ»¤: åŸå§‹={len(image_paths)}, ä¿ç•™={len(input_images)}, "
                           f"è¿‡æ»¤={len(image_paths) - len(input_images)}")
        else:
            # æ‰«æç›®å½•è·å–æ‰€æœ‰å›¾ç‰‡ï¼ˆä»…é™jpgã€jpegã€pngæ ¼å¼ï¼‰
            input_images = []
            img_exts = {'.jpg', '.jpeg', '.png'}
            for root_dir, _, files in os.walk(check_dir):
                for file_name in files:
                    if os.path.splitext(file_name)[1].lower() in img_exts:
                        input_images.append(os.path.join(root_dir, file_name))
        
        # æ‰§è¡Œä¸¤é˜¶æ®µOCRæ£€æµ‹
        ocr_lang = target_languages[0] if target_languages else "ch"
        logger.warning(f"ğŸ” æ‰§è¡ŒOCRæ£€æµ‹ï¼Œä½¿ç”¨è¯­è¨€: {ocr_lang}, åŸå§‹è¯­è¨€åˆ—è¡¨: {target_languages}")
        
        # é€šçŸ¥å¼€å§‹OCRæ£€æµ‹
        notify_ocr_task_progress({
            "id": task_id,
            "remark": f"å¼€å§‹OCRæ£€æµ‹ï¼Œå…±{len(input_images)}å¼ å›¾ç‰‡ï¼Œä½¿ç”¨{ocr_lang}æ¨¡å‹...",
        })
        
        # å®šä¹‰è¿›åº¦å›è°ƒå‡½æ•°
        def ocr_progress_callback(processed, total, stage):
            """OCRæ£€æµ‹è¿›åº¦å›è°ƒ"""
            progress_percent = int((processed / total * 100)) if total > 0 else 0
            notify_ocr_task_progress({
                "id": task_id,
                "processed_images": processed,
                "remark": f"{stage}: {processed}/{total} ({progress_percent}%)",
            })
        
        detection_result = two_stage_service.process_two_stage_detection(
            input_images, 
            lang=ocr_lang,
            progress_callback=ocr_progress_callback
        )
        
        end_time = time.time()
        elapsed_time = end_time - start_time

        # æ£€æŸ¥æ£€æµ‹ç»“æœ
        if not detection_result or not isinstance(detection_result, dict):
            error_msg = "ä¸¤é˜¶æ®µOCRæ£€æµ‹å¤±è´¥"
            logger.error(error_msg)
            notify_ocr_task_progress({
                "id": task_id,
                "status": 'failed',
                "end_time": timezone.now(),
                "remark": error_msg,
            })
            return {"status": "error", "message": error_msg}

        # è·å–æ£€æµ‹ç»“æœç»Ÿè®¡
        final_stats = detection_result.get('final_statistics', {})
        total_hits = final_stats.get('total_hits', 0)
        final_miss = final_stats.get('final_miss', 0)
        overall_hit_rate = final_stats.get('overall_hit_rate', 0)
        
        logger.warning(
            f"ä¸¤é˜¶æ®µOCRæ£€æµ‹å®Œæˆï¼Œæ€»å‘½ä¸­={total_hits} æœ€ç»ˆæœªå‘½ä¸­={final_miss} å‘½ä¸­ç‡={overall_hit_rate:.1f}%ï¼Œ"
            f"è€—æ—¶ {elapsed_time:.2f} ç§’"
        )
        notify_ocr_task_progress({
            "id": task_id,
            "remark": f"ä¸¤é˜¶æ®µOCRæ£€æµ‹å®Œæˆï¼Œè€—æ—¶ {elapsed_time:.2f} ç§’, ç»“æœç»Ÿè®¡ä¸­...",
        })

        # æ„å»ºä¸æ—§æµç¨‹å…¼å®¹çš„ç»“æœåˆ—è¡¨ï¼ˆç”¨äºå†™åº“ä¸æ±‡æ€»ï¼‰
        # ä»ä¸¤é˜¶æ®µæ£€æµ‹ç»“æœä¸­è·å–æ‰€æœ‰å‘½ä¸­è®°å½•å’Œæœªå‘½ä¸­è·¯å¾„
        all_hits_records = detection_result.get('all_hits_records', [])
        final_miss_paths = detection_result.get('final_statistics', {}).get('final_miss_paths', [])
        media_root = settings.MEDIA_ROOT

        # ç”Ÿæˆå…¼å®¹ç»“æœï¼šå°†ä¸¤é˜¶æ®µæ£€æµ‹ç»“æœè½¬æ¢ä¸ºæ•°æ®åº“æ ¼å¼
        notify_ocr_task_progress({
            "id": task_id,
            "remark": f"æ­£åœ¨å¤„ç†OCRç»“æœï¼Œå‘½ä¸­={total_hits}å¼ ï¼Œæœªå‘½ä¸­={final_miss}å¼ ...",
        })
        
        ocr_results = []
        
        # 1. å¤„ç†å‘½ä¸­çš„è®°å½•
        for hit_record in all_hits_records:
            input_path = hit_record.get('input_path', '')
            texts = hit_record.get('rec_texts', [])
            confidences = hit_record.get('rec_scores', [])
            stage = hit_record.get('stage', 'unknown')
            
            # è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼ˆç¡®ä¿ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼‰
            abs_input_path = os.path.abspath(input_path)
            abs_media_root = os.path.abspath(media_root)
            
            # è°ƒè¯•ï¼šè®°å½•ç¬¬ä¸€å¼ å›¾ç‰‡çš„è·¯å¾„ä¿¡æ¯
            if len(ocr_results) == 0:
                logger.info(f"=== è·¯å¾„è°ƒè¯•ä¿¡æ¯ ===")
                logger.info(f"åŸå§‹è·¯å¾„: {input_path}")
                logger.info(f"ç»å¯¹è·¯å¾„: {abs_input_path}")
                logger.info(f"Mediaæ ¹ç›®å½•: {abs_media_root}")
                logger.info(f"æ˜¯å¦ä»¥Mediaå¼€å¤´: {abs_input_path.startswith(abs_media_root)}")
            
            # æ£€æŸ¥è·¯å¾„æ˜¯å¦åœ¨mediaç›®å½•ä¸‹
            if abs_input_path.startswith(abs_media_root):
                rel_path = os.path.relpath(abs_input_path, abs_media_root).replace('\\', '/')
            else:
                logger.warning(f"å›¾ç‰‡è·¯å¾„ä¸åœ¨mediaç›®å½•ä¸‹: {abs_input_path}")
                logger.warning(f"media_root: {abs_media_root}")
                rel_path = os.path.relpath(abs_input_path, abs_media_root).replace('\\', '/')
            
            # è¯»å–å›¾ç‰‡åˆ†è¾¨ç‡
            pic_resolution = ''
            try:
                import numpy as _np
                import cv2 as _cv2
                data = _np.fromfile(input_path, dtype=_np.uint8)
                img_nd = _cv2.imdecode(data, _cv2.IMREAD_COLOR)
                if img_nd is not None:
                    h, w = img_nd.shape[:2]
                    pic_resolution = f"{int(w)}x{int(h)}"
            except Exception:
                pic_resolution = ''
            
            # åˆ›å»º OCR ç»“æœè®°å½•
            ocr_results.append({
                'image_path': rel_path,
                'texts': texts,
                'confidences': confidences,
                'has_match': hit_record.get('has_match', True),  # ä»æ£€æµ‹ç»“æœè·å–å‘½ä¸­çŠ¶æ€
                'pic_resolution': pic_resolution,
                'stage': stage,  # è®°å½•æ£€æµ‹é˜¶æ®µ
                'max_confidence': hit_record.get('max_rec_score', 0.0),
            })
        
        # 2. å¤„ç†æœªå‘½ä¸­çš„è®°å½•ï¼ˆæ²¡æœ‰è¯†åˆ«åˆ°æ–‡æœ¬çš„å›¾ç‰‡ï¼‰
        for miss_path in final_miss_paths:
            # è®¡ç®—ç›¸å¯¹è·¯å¾„
            abs_miss_path = os.path.abspath(miss_path)
            abs_media_root = os.path.abspath(media_root)
            
            if abs_miss_path.startswith(abs_media_root):
                rel_path = os.path.relpath(abs_miss_path, abs_media_root).replace('\\', '/')
            else:
                logger.warning(f"æœªå‘½ä¸­å›¾ç‰‡è·¯å¾„ä¸åœ¨mediaç›®å½•ä¸‹: {abs_miss_path}")
                rel_path = os.path.relpath(abs_miss_path, abs_media_root).replace('\\', '/')
            
            # è¯»å–å›¾ç‰‡åˆ†è¾¨ç‡
            pic_resolution = ''
            try:
                import numpy as _np
                import cv2 as _cv2
                data = _np.fromfile(miss_path, dtype=_np.uint8)
                img_nd = _cv2.imdecode(data, _cv2.IMREAD_COLOR)
                if img_nd is not None:
                    h, w = img_nd.shape[:2]
                    pic_resolution = f"{int(w)}x{int(h)}"
            except Exception:
                pic_resolution = ''
            
            # åˆ›å»ºæœªå‘½ä¸­çš„OCRç»“æœè®°å½•
            ocr_results.append({
                'image_path': rel_path,
                'texts': [],  # æœªå‘½ä¸­ï¼Œæ²¡æœ‰æ–‡æœ¬
                'confidences': [],  # æœªå‘½ä¸­ï¼Œæ²¡æœ‰ç½®ä¿¡åº¦
                'has_match': False,  # æœªå‘½ä¸­
                'pic_resolution': pic_resolution,
                'stage': 'miss',  # æ ‡è®°ä¸ºæœªå‘½ä¸­
                'max_confidence': 0.0,
            })

        # å…³é”®å­—è¿‡æ»¤ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        keyword_filter_config = task_config.get('keyword_filter', {})
        logger.info(f"å…³é”®å­—è¿‡æ»¤é…ç½®: enabled={keyword_filter_config.get('enabled', False)}")
        
        if keyword_filter_config.get('enabled'):
            notify_ocr_task_progress({
                "id": task_id,
                "remark": f"å¼€å§‹å…³é”®å­—è¿‡æ»¤ï¼Œå…±{len(ocr_results)}æ¡ç»“æœ...",
            })
            from apps.ocr.services.keyword_filter import KeywordFilter
            keyword_filter = KeywordFilter(keyword_filter_config)
            original_count = len(ocr_results)
            ocr_results = keyword_filter.filter_results(ocr_results)
            logger.info(f"å…³é”®å­—è¿‡æ»¤: åŸå§‹ç»“æœ={original_count}, è¿‡æ»¤å={len(ocr_results)}")
            
            notify_ocr_task_progress({
                "id": task_id,
                "remark": f"å…³é”®å­—è¿‡æ»¤å®Œæˆ: åŸå§‹={original_count}, åŒ¹é…={len(ocr_results)}",
            })
        else:
            logger.info("å…³é”®å­—è¿‡æ»¤æœªå¯ç”¨ (enabled=False)")
            notify_ocr_task_progress({
                "id": task_id,
                "remark": f"è·³è¿‡å…³é”®å­—è¿‡æ»¤ï¼Œå…±{len(ocr_results)}æ¡ç»“æœ",
            })
        
        # ä¿å­˜ä¸¤é˜¶æ®µæ£€æµ‹ç»“æœåˆ°æ–‡ä»¶ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        try:
            import json as _json
            report_dir = os.path.join(settings.MEDIA_ROOT, 'ocr', 'reports')
            os.makedirs(report_dir, exist_ok=True)
            
            # åˆ†ç¦»å‘½ä¸­å’Œæœªå‘½ä¸­çš„è®°å½•
            hits_only_result = {
                "all_hits_records": detection_result.get('all_hits_records', []),
                "final_statistics": detection_result.get('final_statistics', {}),
            }
            
            # ä¿å­˜å‘½ä¸­ç»“æœ
            result_file = os.path.join(report_dir, f"{task.id}_two_stage_result.json")
            with open(result_file, 'w', encoding='utf-8') as fp:
                _json.dump(hits_only_result, fp, ensure_ascii=False, indent=2)
            logger.warning(f"ä¸¤é˜¶æ®µæ£€æµ‹ç»“æœå·²å†™å…¥: {result_file}")
            
            # ä¿å­˜æœªå‘½ä¸­ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            miss_records = detection_result.get('all_miss_records', [])
            if miss_records:
                miss_file = os.path.join(report_dir, f"{task.id}_miss_details.json")
                miss_result = {
                    "total_miss": len(miss_records),
                    "miss_records": miss_records,
                }
                with open(miss_file, 'w', encoding='utf-8') as fp:
                    _json.dump(miss_result, fp, ensure_ascii=False, indent=2)
                logger.warning(f"æœªå‘½ä¸­è¯¦æƒ…å·²å†™å…¥: {miss_file}")
        except Exception as _result_err:
            logger.warning(f"å†™å…¥ä¸¤é˜¶æ®µæ£€æµ‹ç»“æœå¤±è´¥(å¿½ç•¥): {_result_err}")

        if not ocr_results:
            logger.warning("æœªæ£€æµ‹åˆ°ä»»ä½•å›¾ç‰‡ï¼Œä»»åŠ¡ç»“æŸ")
            notify_ocr_task_progress({
                "id": task_id,
                "status": 'completed',
                "end_time": timezone.now(),
                "total_images": len(input_images),
                "processed_images": 0,
                "matched_images": 0,
                "match_rate": 0.0,
                "remark": "æœªæ£€æµ‹åˆ°ä»»ä½•å›¾ç‰‡ï¼Œä»»åŠ¡ç»“æŸ",
            })
            return {"status": "success", "task_id": task_id}

        # æ‰¹é‡è®°å½• OCRResult & ç»Ÿè®¡æœ€ç»ˆå‘½ä¸­æ•°
        notify_ocr_task_progress({
            "id": task_id,
            "remark": f"æ­£åœ¨ä¿å­˜OCRç»“æœåˆ°æ•°æ®åº“ï¼Œå…±{len(ocr_results)}æ¡...",
        })
        
        new_results = []
        total_matches = 0
        for item in ocr_results:
            img_full_path = os.path.join(media_root, item['image_path'])
            img_hash = OCRService.calculate_image_hash(img_full_path)
            if enable_cache and img_hash in hit_hashes:
                # å¦‚æœæœ¬æ¬¡ä»»åŠ¡å¯ç”¨ç¼“å­˜å¹¶ä¸”æ­¤ç¼“å­˜å·²å­˜åœ¨ï¼Œåˆ™è·³è¿‡å†™åº“
                continue
            obj = OCRResult(
                task=task,
                image_hash=img_hash,
                image_path=item.get('image_path', '').replace('\\', '/'),
                texts=item.get('texts', []),
                languages=item.get('languages', {}),
                has_match=item.get('has_match', False),
                confidences=item.get('confidences', []),
                max_confidence=item.get('max_confidence', 0.0),
                processing_time=item.get('processing_time', 0),
                pic_resolution=item.get('pic_resolution', ''),
                team_id=task.team_id
            )
            new_results.append(obj)
            texts_present = bool(item.get('texts'))
            if texts_present and item.get('has_match', False):
                total_matches += 1

        OCRResult.objects.bulk_create(new_results)
        logger.warning(f"æ‰¹é‡æ’å…¥ {len(new_results)} æ¡OCRç»“æœåˆ°æ•°æ®åº“")
        
        notify_ocr_task_progress({
            "id": task_id,
            "verified_images": task.total_verified,
            "remark": f"å·²ä¿å­˜{len(new_results)}æ¡ç»“æœåˆ°æ•°æ®åº“",
        })
        
        # å¼ºåˆ¶æäº¤æ•°æ®åº“äº‹åŠ¡
        from django.db import transaction
        transaction.commit()
        
        # çŸ­æš‚å»¶è¿Ÿç¡®ä¿æ•°æ®åº“æ“ä½œå®Œå…¨å®Œæˆ
        time.sleep(0.2)
        
        # è®°å½•ocrç¼“å­˜
        OCRCache.record_cache(task_id)


        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        notify_ocr_task_progress({
            "id": task_id,
            "remark": "æ­£åœ¨ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š...",
        })
        
        logger.warning("å¼€å§‹ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š")
        _generate_summary_report(task, ocr_results, target_languages)
        logger.warning("æ±‡æ€»æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        
        notify_ocr_task_progress({
            "id": task_id,
            "remark": "æ±‡æ€»æŠ¥å‘Šç”Ÿæˆå®Œæˆ",
        })

        # å®Œæˆè¿›åº¦ - ç›´æ¥ä½¿ç”¨å·²çŸ¥çš„ç»Ÿè®¡æ•°æ®æ›´æ–°ä»»åŠ¡
        try:
            logger.warning(f"å¼€å§‹æ›´æ–°ä»»åŠ¡ {task_id} çš„ç»Ÿè®¡æ•°æ®...")
            
            # ç›´æ¥è®¡ç®—ç»Ÿè®¡æ•°æ®ï¼Œä¸ä¾èµ–å¤æ‚çš„æŸ¥è¯¢
            total_processed = len(ocr_results)
            total_matched = sum(1 for item in ocr_results if item.get('has_match', False))
            match_rate = round((total_matched / total_processed * 100), 2) if total_processed > 0 else 0.0
            
            # ç›´æ¥æ›´æ–°ä»»åŠ¡ç»Ÿè®¡å­—æ®µ
            task.processed_images = total_processed
            task.matched_images = total_matched
            task.match_rate = match_rate
            task.save(update_fields=["processed_images", "matched_images", "match_rate"])
            
            logger.warning(f"ä»»åŠ¡ {task_id} ç»Ÿè®¡æ•°æ®æ›´æ–°å®Œæˆ: æ€»æ•°={total_processed}, åŒ¹é…æ•°={total_matched}, åŒ¹é…ç‡={match_rate}%")
            
            notify_ocr_task_progress({
                "id": task_id,
                "status": 'completed',
                "end_time": timezone.now(),
                "total_images": total_processed,
                "processed_images": total_processed,
                "matched_images": total_matched,
                "match_rate": match_rate,
                "remark": "âœ… ä»»åŠ¡æ‰§è¡Œå®Œæ¯•",
            })
        except Exception as _fin_err:
            logger.warning(f"å®Œæˆè¿›åº¦æ›´æ–°å¤±è´¥(å¿½ç•¥): {_fin_err}")

        return {"status": "success", "task_id": task_id}

    except Exception as e:
        logger.error(f"ä»»åŠ¡å¤„ç†å¤±è´¥: {str(e)}")
        # è®°å½•è¯¦ç»†çš„å¼‚å¸¸å †æ ˆ
        import traceback
        logger.error(traceback.format_exc())

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
        try:
            notify_ocr_task_progress({
                "id": task_id,
                "status": 'failed',
                "end_time": timezone.now(),
                "remark": f"ä»»åŠ¡å¤„ç†å¤±è´¥: {str(e)}",
            })
        except Exception:
            pass

        return {"status": "error", "message": str(e)}


def _generate_summary_report(task, results, target_languages):
    """ç”ŸæˆOCRæ±‡æ€»æŠ¥å‘Šï¼ˆæŒ‰åŠ¨æ€ç›®æ ‡è¯­è¨€å‘½ä¸­ï¼‰ã€‚

    Args:
        task (OCRTask): å½“å‰ä»»åŠ¡å®ä¾‹ã€‚
        results (list[dict]): è¯†åˆ«ç»“æœåˆ—è¡¨ï¼Œå…ƒç´ åŒ…å« `image_path`ã€`texts` ç­‰å­—æ®µã€‚
        target_languages (list[str] | None): ç›®æ ‡è¯­è¨€ä»£ç åˆ—è¡¨ï¼›None/ç©ºé»˜è®¤ ['ch']ã€‚

    Returns:
        None: ç»“æœç›´æ¥å†™å…¥æŠ¥å‘Šæ–‡ä»¶ï¼Œå¹¶æ›´æ–° `task.config['report_file']`ã€‚

    Raises:
        æ— æ˜¾å¼æŠ›å‡ºã€‚å†…éƒ¨å¼‚å¸¸å·²åšä¿æŠ¤æ€§å¤„ç†å¹¶è®°å½•æ—¥å¿—ã€‚

    Example:
        >>> _generate_summary_report(task, results, ['ch','en'])

    Notes:
        - å‘½ä¸­åˆ¤å®šéµå¾ªâ€œä»»æ„ç›®æ ‡è¯­è¨€å‘½ä¸­å³è§†ä¸ºå‘½ä¸­â€ã€‚
        - è·¯å¾„ç»Ÿä¸€ç» `PathUtils.normalize_path` è§„èŒƒåŒ–ã€‚
        - å°†åœ¨ `MEDIA_ROOT/ocr/reports/` ç›®å½•ç”Ÿæˆä¸¤ä¸ªæ–‡ä»¶:
          1) `{task.id}_ocr_summary.json` æœ¬æ¬¡ä»»åŠ¡çš„ç»“æ„åŒ–æ±‡æ€»
          2) `ocr_summary.json` æŒ‡å‘æœ€è¿‘ä¸€æ¬¡ç”Ÿæˆçš„è¦†ç›–å¼æ±‡æ€»
    """
    # ç»Ÿè®¡ä¿¡æ¯
    total_images = len(results)
    matched_images = []

    # ç­›é€‰åŒ…å«ç›®æ ‡è¯­è¨€çš„å›¾ç‰‡ï¼ˆå‘½ä¸­è§„åˆ™ï¼šåŒ…å«ä»»ä¸€ç›®æ ‡è¯­è¨€æ–‡å­—å³ä¸ºå‘½ä¸­ï¼‰
    for result in results:
        # è·³è¿‡å¤„ç†å¤±è´¥çš„å›¾ç‰‡
        if 'error' in result:
            continue

        texts = result.get('texts', [])
        if not _is_language_hit(texts, target_languages):
            continue

        # è·å–æ–‡ä»¶ä¿¡æ¯
        image_path = result.get('image_path', '')
        image_path = PathUtils.normalize_path(image_path)
        file_name = os.path.basename(image_path)

        try:
            # å°è¯•è·å–æ–‡ä»¶å¤§å°ï¼ˆç›¸å¯¹è·¯å¾„æ‹¼æ¥ MEDIA_ROOTï¼‰
            if os.path.isabs(image_path):
                file_size = os.path.getsize(image_path) / 1024  # KB
            else:
                full_path = os.path.join(settings.MEDIA_ROOT, image_path)
                file_size = os.path.getsize(full_path) / 1024  # KB
        except Exception:
            file_size = 0

        matched_texts = _filter_texts_by_languages(texts, target_languages)

        matched_images.append({
            'path': image_path,
            'name': file_name,
            'size': file_size,
            'time': result.get('time_cost', 0),
            'texts': texts,
            'matched_texts': ' '.join(matched_texts),
        })

    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    matched_count = len(matched_images)
    matched_rate = (matched_count / total_images * 100) if total_images > 0 else 0

    # ç”ŸæˆæŠ¥å‘Šå†…å®¹ï¼ˆåŠ¨æ€ç›®æ ‡è¯­è¨€ï¼‰
    now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    langs_str = ','.join(target_languages or ['ch'])
    report = f"""åŒ…å«ç›®æ ‡è¯­è¨€çš„å›¾ç‰‡æ£€æµ‹ç»“æœ
==================================================
ç”Ÿæˆæ—¶é—´: {now}
ç›®æ ‡è¯­è¨€: {langs_str}
æ€»å¤„ç†å›¾ç‰‡æ•°: {total_images}
å‘½ä¸­å›¾ç‰‡æ•°: {matched_count}
å‘½ä¸­ç‡: {matched_rate:.1f}%

å‘½ä¸­çš„å›¾ç‰‡åˆ—è¡¨:
------------------------------"""

    # æ·»åŠ æ¯å¼ å›¾ç‰‡çš„è¯¦ç»†ä¿¡æ¯
    for i, img in enumerate(matched_images, 1):
        report += f"""
{i}. å›¾ç‰‡ä¿¡æ¯:
   æ–‡ä»¶è·¯å¾„: {img['path']}
   æ–‡ä»¶å: {img['name']}
   æ–‡ä»¶å¤§å°: {img['size']:.2f} KB
   å¤„ç†æ—¶é—´: {img['time']:.2f}ç§’
   å‘½ä¸­æ–‡æœ¬: {img['matched_texts']}
   å®Œæ•´æ–‡æœ¬: {' '.join(img['texts'])}"""

    # æ·»åŠ è¯´æ˜ä¿¡æ¯
    report += """

1ã€è¯†åˆ«ç»“æŸåçš„ç»“æœæŒ‰ç…§ä»¥ä¸Šæ ¼å¼æ±‡æ€»è¾“å‡ºã€‚
2ã€ä¸å†å•å¼ å›¾ç‰‡å•ä¸ªæ–‡ä»¶è¾“å‡ºã€‚"""

    # ä¿å­˜æŠ¥å‘Š
    report_dir = PathUtils.get_ocr_reports_dir()
    os.makedirs(report_dir, exist_ok=True)

    # åŒæ­¥è¾“å‡ºç»“æ„åŒ– JSON æ±‡æ€»ï¼Œä¾¿äºå‰ç«¯æˆ–å…¶ä»–å·¥å…·ä½¿ç”¨
    try:
        import json
        json_items = []
        for img in matched_images:
            json_items.append({
                'path': img['path'],
                'name': img['name'],
                'matched_texts': img['matched_texts'],
                # æ–°å¢å­—æ®µ, ä»ç»“æœå›å¡«: åˆ†è¾¨ç‡ã€åƒç´ ã€å‚æ•°å·®å¼‚ã€ç½®ä¿¡åº¦ã€æ¨¡å¼
                'resolution': None,
                'pixels': None,
                'param_diff': None,
                'confidences': None,
                'mode_display': None,
            })
        # è‹¥åŸå§‹ results ä¸­åŒ…å« used_preset/mode_display, åˆ™è¿›è¡Œå¯¹é½åˆå¹¶
        try:
            # å»ºç«‹ path -> extras çš„æ˜ å°„
            extras = {}
            for r in results:
                if 'error' in r:
                    continue
                p = PathUtils.normalize_path(r.get('image_path', ''))
                extras[p] = {
                    'mode_display': r.get('mode_display'),
                    'resolution': r.get('resolution'),
                    'pixels': r.get('pixels'),
                    'param_diff': r.get('param_diff'),
                    'confidences': r.get('confidences'),
                }
            # å›å¡«
            for item in json_items:
                ext = extras.get(item['path']) or {}
                if ext.get('mode_display') is not None:
                    item['mode_display'] = ext.get('mode_display')
                if ext.get('resolution') is not None:
                    item['resolution'] = ext.get('resolution')
                if ext.get('pixels') is not None:
                    item['pixels'] = ext.get('pixels')
                if ext.get('param_diff') is not None:
                    item['param_diff'] = ext.get('param_diff')
                if ext.get('confidences') is not None:
                    item['confidences'] = ext.get('confidences')
        except Exception:
            pass

        summary_json = {
            'task_id': task.id,
            'generated_at': now,
            'target_languages': target_languages or ['ch'],
            'total_images': total_images,
            'matched_count': matched_count,
            'matched_rate': round(matched_rate, 2),
            'items': json_items,
        }
        json_dir = report_dir
        json_file = os.path.join(json_dir, f"{task.id}_ocr_summary.json")
        with open(json_file, 'w', encoding='utf-8') as jf:
            json.dump(summary_json, jf, ensure_ascii=False, indent=2)
        # ç”Ÿæˆè¦†ç›–å¼åˆ«åæ–‡ä»¶, æ–¹ä¾¿ç”¨æˆ·ç›´æ¥æŸ¥æ‰¾æœ€è¿‘ä¸€æ¬¡çš„æ±‡æ€»
        alias_file = os.path.join(json_dir, "ocr_summary.json")
        with open(alias_file, 'w', encoding='utf-8') as af:
            json.dump(summary_json, af, ensure_ascii=False, indent=2)
        # ä½¿ç”¨ warning çº§åˆ«ä¾¿äºåœ¨æ§åˆ¶å°çœ‹åˆ°å®Œæ•´è·¯å¾„
        logger.warning(f"OCR JSONæ±‡æ€»å·²ç”Ÿæˆ: {json_file}")
        logger.warning(f"OCR æœ€è¿‘ä¸€æ¬¡æ±‡æ€»(è¦†ç›–): {alias_file}")
    except Exception as je:
        logger.error(f"ç”ŸæˆOCR JSONæ±‡æ€»å¤±è´¥: {je}")

    # ä»…ç”ŸæˆJSON, ä¸å†ç”Ÿæˆtxt; ä¿æŒä»»åŠ¡å…¶ä»–ä¿¡æ¯ä¸å˜

    logger.info(
        f"OCRè¯†åˆ«ç»Ÿè®¡: æ€»å›¾ç‰‡æ•°={total_images}, å‘½ä¸­å›¾ç‰‡æ•°={matched_count}, å‘½ä¸­ç‡={matched_rate:.1f}%"
    )


def _process_results(task, results, target_languages):
    """
    å¤„ç†OCRè¯†åˆ«ç»“æœï¼ˆé€šç”¨åŠ¨æ€è¯­è¨€å‘½ä¸­ï¼‰ã€‚

    Args:
        task (OCRTask): å½“å‰ä»»åŠ¡å®ä¾‹ã€‚
        results (list[dict]): è¯†åˆ«ç»“æœåˆ—è¡¨ï¼Œå…ƒç´ åŒ…å« `image_path`ã€`texts` ç­‰å­—æ®µã€‚
        target_languages (list[str] | None): ç›®æ ‡è¯­è¨€ä»£ç åˆ—è¡¨ï¼›None/ç©ºé»˜è®¤ ['ch']ã€‚

    Returns:
        dict: åŒ…å«ä»¥ä¸‹é”®ï¼š
            - processed_results (list[dict]): é™„å¸¦ `languages`/`has_match` çš„ç»“æœåˆ—è¡¨
            - matched_images (list[dict]): å‘½ä¸­å›¾ç‰‡çš„ç²¾ç®€ä¿¡æ¯
            - matched_count (int): å‘½ä¸­æ•°é‡
            - matched_rate (float): å‘½ä¸­ç‡ï¼ˆ0~100ï¼‰

    Raises:
        æ— æ˜¾å¼æŠ›å‡ºã€‚å†…éƒ¨å¼‚å¸¸ä¼šåœ¨å¿…è¦å¤„è¢«ä¿æŠ¤æ€§æ•è·å¹¶è®°å½•ã€‚

    Example:
        >>> data = _process_results(task, results, ['ch','en'])
        >>> data['matched_count']

    Notes:
        - å‘½ä¸­è§„åˆ™ï¼šåªè¦åŒ…å«ä»»ä¸€ç›®æ ‡è¯­è¨€æ–‡æœ¬å³å‘½ä¸­ã€‚
        - é¿å…ç¡¬ç¼–ç è¯­è¨€ï¼›æŒ‰è¾“å…¥åŠ¨æ€å†³å®šã€‚
        - ä¸¥æ ¼æ§åˆ¶ç¼©è¿›ä¸å¾ªç¯å±‚çº§ï¼Œä¿è¯å¯ç»´æŠ¤æ€§ä¸å¯è¯»æ€§ã€‚
    """
    logger.warning(f"å¼€å§‹å¤„ç†OCRç»“æœï¼Œå…± {len(results)} ä¸ªç»“æœ")

    processed_results = []
    matched_images = []

    safe_langs = target_languages or ['ch']

    for result in results:
        if 'error' in result:
            continue

        texts = result.get('texts', [])
        languages = {}
        for lang in safe_langs:
            try:
                if OCRService.check_language_match(texts, lang):
                    languages[lang] = True
            except Exception:
                continue
        has_match = bool(languages)

        enriched = {
            **result,
            'languages': languages,
            'has_match': has_match,
        }
        processed_results.append(enriched)

        if has_match:
            image_path = PathUtils.normalize_path(result.get('image_path', ''))
            file_name = os.path.basename(image_path)
            try:
                if os.path.isabs(image_path):
                    file_size = os.path.getsize(image_path) / 1024  # KB
                else:
                    full_path = os.path.join(settings.MEDIA_ROOT, image_path)
                    file_size = os.path.getsize(full_path) / 1024  # KB
            except Exception:
                file_size = 0

            matched_texts = _filter_texts_by_languages(texts, safe_langs)

            matched_images.append({
                'path': image_path,
                'name': file_name,
                'size': file_size,
                'time': result.get('time_cost', 0),
                'texts': texts,
                'matched_texts': ' '.join(matched_texts),
            })

    total_images = len(results)
    matched_count = len(matched_images)
    matched_rate = (matched_count / total_images * 100) if total_images > 0 else 0

    logger.info(
        f"OCRè¯†åˆ«ç»Ÿè®¡: æ€»å›¾ç‰‡æ•°={total_images}, å‘½ä¸­å›¾ç‰‡æ•°={matched_count}, å‘½ä¸­ç‡={matched_rate:.1f}%"
    )

    # å¯æŒ‰éœ€è¿”å›ç»“æ„åŒ–ç»“æœï¼Œå½“å‰ä¸å½±å“æ—¢æœ‰è°ƒç”¨æ–¹
    return {
        'processed_results': processed_results,
        'matched_images': matched_images,
        'matched_count': matched_count,
        'matched_rate': matched_rate,
    }

@shared_task()
def binding_translated_image(task_id: str):
    """
    OCR ä»»åŠ¡å†æ¬¡å‘èµ·å¯¹æ¯”å¤„ç†ä»»åŠ¡ï¼Œå¯¹æ¯”çš„å¯¹è±¡ä¸ºï¼š
    a. task_id ç”Ÿæˆçš„ OcrResult ç»“æœ
    b. ç”¨æˆ·æŒ‡å®šçš„è¿œç¨‹ Git ä»“åº“ã€åˆ†æ”¯ã€è·¯å¾„ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
    å¸®åŠ©ç”¨æˆ·åœ¨ OcrResult çš„æ¯ä¸ªè®°å½•ä¸­æ ‡è¯†å‡ºæ˜¯å¦åœ¨è¿œç¨‹ä»“åº“ä¸­å­˜åœ¨å¯¹åº”çš„å·²ç¿»è¯‘çš„æ–‡ä»¶ã€‚
    Args:
        task_id (int): OCR ä»»åŠ¡ IDã€‚
    """
    logger.info(f"å¼€å§‹å¤„ç†å¯¹æ¯”ä»»åŠ¡: {task_id}")

    def update_trans_repo_status(status, error=""):
        """æ›´æ–°ç¿»è¯‘ä»“åº“å…³è”çŠ¶æ€"""
        if task.config and 'trans_repo' in task.config:
            task.config['trans_repo']['status'] = status
            task.config['trans_repo']['error'] = error
            notify_ocr_task_progress({
                "id": task_id,
                "config": task.config,
            })
    
    try:
        # step1. ä¸€äº›é¢„æ ¡éªŒ
        task: OCRTask = OCRTask.objects.all_teams().filter(id=task_id).first()
        if not task:
            logger.error(f"OCRä»»åŠ¡ä¸å­˜åœ¨: id={task_id}")
            return

        task_config = task.config or {}
        trans_repo = task_config.get('trans_repo')
        if not trans_repo:
            msg = f"OCRä»»åŠ¡æœªé…ç½®ç¿»è¯‘ä»“åº“å¯¹ç…§å‚æ•°: id={task_id}"
            logger.error(msg)
            return

        try:
            trans_repo_config = TransRepoConfig(**trans_repo)
        except Exception as e:
            msg = f"OCRä»»åŠ¡å¯¹æ¯”ä»“åº“é…ç½®é”™è¯¯: {str(e)}"
            logger.error(msg)
            update_trans_repo_status("failed", msg)
            return

        results = list(task.related_results) # è½¬æ¢ä¸ºåˆ—è¡¨ä»¥ä¾¿å¤šæ¬¡ä½¿ç”¨
        if len(results) == 0:
            logger.warning(f"OCRä»»åŠ¡æ— ç›¸å…³ç»“æœï¼Œè·³è¿‡å¯¹æ¯”å¤„ç†: id={task_id}")
            update_trans_repo_status("completed")
            return

        # step2. å°†ç¿»è¯‘ä»“åº“å…‹éš†åˆ°æœ¬åœ°ç›®å½•

        download_result = trans_repo_config.download_repo()
        if not download_result.success:
            msg = f"å¯¹æ¯”ä»“åº“ä¸‹è½½å¤±è´¥: {download_result.message}"
            logger.error(msg)
            update_trans_repo_status("failed", msg)
            return

        # step3. å»ºç«‹ç´¢å¼• (æ€§èƒ½ä¼˜åŒ–å…³é”®ç‚¹)
        try:
            # é¢„å…ˆæ‰«æç›®å½•å»ºç«‹ Hash Set ç´¢å¼•ï¼Œé¿å…åç»­å¾ªç¯ä¸­é¢‘ç¹ IO
            trans_repo_config.build_repo_index()
        except Exception as e:
            msg = f"å»ºç«‹ç´¢å¼•å¤±è´¥: {e}"
            logger.error(msg)
            update_trans_repo_status("failed", msg)
            return

        # step4. éå† OCR ç»“æœï¼šåˆ©ç”¨ç´¢å¼•åŒ¹é…
        update_results = []
        match_count = 0
        
        for ocr_result in results:
            # ä½¿ç”¨ match_image_path (å†…å­˜æŸ¥æ‰¾) ä»£æ›¿ locate_trans_image_path (ç£ç›˜æŸ¥æ‰¾)
            trans_image_path = trans_repo_config.match_image_path(ocr_result.image_path)
            
            # åªæœ‰çŠ¶æ€æ”¹å˜æˆ–è·¯å¾„æ”¹å˜æ—¶æ‰æ›´æ–°ï¼Œæˆ–è€…å…¨éƒ¨æ›´æ–°
            ocr_result.is_translated = trans_image_path is not None
            ocr_result.trans_image_path = trans_image_path
            update_results.append(ocr_result)
            
            if ocr_result.is_translated:
                match_count += 1

        # step5. æ‰¹é‡æ›´æ–°ç»“æœ
        if update_results:
            OCRResult.objects.bulk_update(
                update_results,
                fields=['is_translated', 'trans_image_path']
            )
        
        # æ›´æ–°çŠ¶æ€ä¸ºå®Œæˆ
        update_trans_repo_status("completed")
        
        logger.info(f"å¯¹æ¯”å®Œæˆ: id={task_id}, æ€»æ•°={len(results)}, åŒ¹é…={match_count}")
        
        # å‘é€å®Œæˆé€šçŸ¥

    except Exception as e:
        logger.error(f"å¯¹æ¯”ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {str(e)}")
        logger.error(traceback.format_exc())
        update_trans_repo_status("failed", str(e))


def compress_image(path):
    if not path: return ""
    abs_path = os.path.join(settings.MEDIA_ROOT, path)
    if not os.path.exists(abs_path): return ""

    try:
        with Image.open(abs_path) as img:
            buffer = io.BytesIO()
            # ä¼˜å…ˆå°è¯• WebP æ ¼å¼ (ä½“ç§¯å°ä¸”è´¨é‡å¥½ï¼Œç‰¹åˆ«é€‚åˆå¸¦æ–‡å­—çš„æˆªå›¾)
            try:
                # å¦‚æœæ˜¯ RGBA æ¨¡å¼ï¼ŒWebP å¯ä»¥ä¿ç•™é€æ˜åº¦ï¼›å¦‚æœæ˜¯å…¶ä»–æ¨¡å¼è½¬ RGB
                if img.mode not in ('RGB', 'RGBA'):
                    img = img.convert('RGB')

                # quality=75: è§†è§‰æ— æŸ
                # method=4: é»˜è®¤å‹ç¼©é€Ÿåº¦/è´¨é‡å¹³è¡¡
                img.save(buffer, format="WEBP", quality=75, method=4)
                mime_type = "image/webp"
            except Exception:
                # å›é€€åˆ° JPEG
                buffer.seek(0)
                buffer.truncate()
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                # quality=75: ä¿è¯æ¸…æ™°åº¦
                # subsampling=0: å…³é—­è‰²åº¦æŠ½æ ·ï¼Œé˜²æ­¢æ–‡å­—è¾¹ç¼˜é¢œè‰²å¤±çœŸ(å˜çº¢/å˜ç³Š)
                # optimize=True: ä¼˜åŒ– Huffman è¡¨ï¼Œå‡å°ä½“ç§¯
                img.save(buffer, format="JPEG", quality=75, optimize=True, subsampling=0)
                mime_type = "image/jpeg"

            img_str = base64.b64encode(buffer.getvalue()).decode()
            return f"data:{mime_type};base64,{img_str}"
    except Exception as e:
        logger.error(f"å›¾ç‰‡å¤„ç†å¤±è´¥ {abs_path}: {e}")
        return ""

@shared_task()
def export_offline_html_task(task_id: str, filter_data: dict = None, file_name: str = None):
    """
    å¯¼å‡ºç¦»çº¿HTMLæŠ¥å‘Šä»»åŠ¡
    """
    logger.info(f"å¼€å§‹å¯¼å‡ºç¦»çº¿æŠ¥å‘Š: {task_id}, ç­›é€‰æ¡ä»¶: {filter_data}")
    try:
        task = OCRTask.objects.all_teams().get(id=task_id)
        
        # åºåˆ—åŒ–æ•°æ®
        task_data = OCRTaskSerializer(task).data
        
        # æ„å»ºæŸ¥è¯¢é›†
        results_qs = task.related_results.all().order_by('id')
        
        if filter_data:
            # 1. has_match
            has_match = filter_data.get('has_match')
            if has_match is not None:
                results_qs = results_qs.filter(has_match=has_match)
                
            # 2. result_type
            result_type = filter_data.get('result_type')
            if result_type:
                results_qs = results_qs.filter(result_type=result_type)
                
            # 3. is_verified
            is_verified = filter_data.get('is_verified')
            if is_verified is not None:
                results_qs = results_qs.filter(is_verified=is_verified)
                
            # 4. is_translated
            is_translated = filter_data.get('is_translated')
            if is_translated is not None:
                results_qs = results_qs.filter(is_translated=is_translated)
                
            # 5. keyword (search in texts)
            keyword = filter_data.get('keyword')
            if keyword:
                matching_ids = []
                for result in results_qs:
                    if result.texts:
                        for text in result.texts:
                            if keyword.lower() in text.lower():
                                matching_ids.append(result.id)
                                break
                results_qs = results_qs.filter(id__in=matching_ids)

        # åˆ†æ‰¹å¤„ç†ç»“æœï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½è¿‡å¤šæ•°æ®å¯¼è‡´å†…å­˜æº¢å‡º
        results_data = []
        batch_size = 50  # æ¯æ‰¹å¤„ç†çš„æ•°é‡
        total_count = results_qs.count()
        
        logger.info(f"å¾…å¤„ç†ç»“æœæ€»æ•°: {total_count}ï¼Œæ‰¹æ¬¡å¤§å°: {batch_size}")
        
        # ä½¿ç”¨æ¸¸æ ‡åˆ†é¡µæˆ–åˆ‡ç‰‡è¿›è¡Œåˆ†æ‰¹å¤„ç†
        for start in range(0, total_count, batch_size):
            end = min(start + batch_size, total_count)
            # è·å–å½“å‰æ‰¹æ¬¡çš„æ•°æ®
            batch_results = results_qs[start:end]
            batch_data = OCRResultSerializer(batch_results, many=True).data
            
            # å¤„ç†å½“å‰æ‰¹æ¬¡çš„å›¾ç‰‡è½¬Base64
            for item in batch_data:
                # å¤„ç†åŸå›¾
                item['image_url'] = compress_image(item.get('image_path'))
                
                # å¤„ç†ç¿»è¯‘å›¾
                item['trans_image_url'] = compress_image(item.get('trans_image_path'))
            
            # å°†å¤„ç†å¥½çš„æ‰¹æ¬¡æ•°æ®æ·»åŠ åˆ°æ€»åˆ—è¡¨ä¸­
            results_data.extend(batch_data)
            
            # æ‰“å°è¿›åº¦
            progress = (end / total_count) * 100
            logger.info(f"å¯¼å‡ºè¿›åº¦: {end}/{total_count} ({progress:.1f}%)")

        # è¾…åŠ©å‡½æ•°ï¼šå°†æšä¸¾ç±»è½¬æ¢ä¸ºå‰ç«¯å¯ç”¨å­—å…¸
        def enum_to_dict(enum_cls):
            res = {}
            for name, member in enum_cls.__members__.items():
                res[name] = {
                    'value': member.value,
                    'label': member.label,
                    'order': getattr(member, 'order', 0)
                }
            return res

        enums_data = {
            'ocrResultTypeEnum': enum_to_dict(ocrResultTypeEnum),
            'ocrIsMatchEnum': enum_to_dict(ocrIsMatchEnum),
            'ocrIsVerifiedEnum': enum_to_dict(ocrIsVerifiedEnum),
            'ocrIsTranslatedEnum': enum_to_dict(ocrIsTranslatedEnum),
        }

        # è¯»å–é™æ€èµ„æºæ–‡ä»¶å†…å®¹ï¼Œç”¨äºç¦»çº¿æŠ¥å‘ŠåµŒå…¥
        # é™æ€æ–‡ä»¶ä½äº apps/ocr/templates/ocr/ ç›®å½•ä¸‹
        template_dir = os.path.join(settings.BASE_DIR, 'apps', 'ocr', 'templates', 'ocr')
        
        def read_static_content(filename):
            try:
                file_path = os.path.join(template_dir, filename)
                if os.path.exists(file_path):
                    with open(file_path, 'r', encoding='utf-8') as f:
                        return f.read()
                logger.warning(f"ç¦»çº¿æŠ¥å‘Šé™æ€èµ„æºæœªæ‰¾åˆ°: {file_path}")
                return ""
            except Exception as e:
                logger.error(f"è¯»å–é™æ€èµ„æºå¤±è´¥ {filename}: {e}")
                return ""

        # æ¸²æŸ“æ¨¡æ¿
        context = {
            # åµŒå…¥é™æ€èµ„æº
            'vue_js': read_static_content('vue.global.prod.js'),
            'element_css': read_static_content('element-plus.index.css'),
            'element_js': read_static_content('element-plus.index.min.js'),
            'element_icons_js': read_static_content('element-plus.icons-vue.js'),
            # æ•°æ®
            'task': task_data,
            'task_json': json.dumps(task_data),
            'results_json': json.dumps(results_data),
            'enums_json': json.dumps(enums_data),
            'filter_data_json': json.dumps(filter_data or {}),
        }
        
        html_content = render_to_string('ocr/offline_report.html', context)
        
        # ä¿å­˜æ–‡ä»¶
        report_dir = PathUtils.get_ocr_reports_dir()
        os.makedirs(report_dir, exist_ok=True)
        
        if not file_name:
            file_name = f"ocr_report_{task.id}_offline.html"
            
        file_path = os.path.join(report_dir, file_name)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
            
        logger.info(f"ç¦»çº¿æŠ¥å‘Šç”ŸæˆæˆåŠŸ: {file_path}")
        
        # å‘é€é€šçŸ¥ï¼ˆå¯é€‰ï¼Œå¦‚æœå‰ç«¯é€šè¿‡è½®è¯¢æˆ–SSEæ¥æ”¶ï¼‰
        notify_ocr_task_progress({
            "id": task_id,
            "offline_report_url": f"/media/ocr/reports/{file_name}",
            "msg": "ç¦»çº¿æŠ¥å‘Šç”ŸæˆæˆåŠŸ"
        })
        
    except Exception as e:
        logger.error(f"å¯¼å‡ºç¦»çº¿æŠ¥å‘Šå¤±è´¥: {e}")
        logger.error(traceback.format_exc())




